#pragma OPENCL EXTENSION cl_viv_vx_extension : enable

#include "cl_viv_vx_ext.h"

_viv_uniform float logE;
_viv_uniform float twoLogE;
_viv_uniform float rlogE;
_viv_uniform float a_val;

float4 sigmoid_(float4 x)
{
    x *= -logE;
    x = 1 + exp2(x);
    return 1 / x;
}

float4 sqrt_(float4 x)
{
    return sqrt(x);
}

float4 rsqrt_(float4 x)
{
    return rsqrt(x);
}

float4 tanh_(float4 x)
{
    x *= -twoLogE;
    x = 1 + exp2(x);
    x = 1 / x;
    return a_val * (2 * x - 1);
}

float4 softRelu_(float4 x)
{
    x *= logE;
    x = exp2(x);
    x += 1;
    x = log2(x);
    return x * rlogE;
}

float4 square_(float4 x)
{
    return x * x;
}

_viv_uniform float input_scale;
_viv_uniform float input_tail;
_viv_uniform float output_scale;
_viv_uniform float output_zp;
_viv_uniform VXC_512Bits uniExtract8Data_2x8;
_viv_uniform VXC_512Bits uniDatatoFp32Part0_4x4;
_viv_uniform VXC_512Bits uniDatatoFp32Part1_4x4;

#define TENSOR_TRANSCENDENTAL(funcName, src_type_name, dst_type_name, src_type, src_copy_type, convert_type, dst_type, dst_copy_type) \
    __kernel void activation_##funcName##_##src_type_name##to##dst_type_name( \
    __read_only  image2d_array_t  input, \
    __write_only image2d_array_t  output \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0); \
    src_type      src0; \
    src_copy_type src1; \
    VXC_ReadImage2DArray(src0, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    _viv_asm(COPY, src1, src0, 16); \
 \
    float4 vecA; \
    float4 vecB; \
    VXC_DP4x4(vecA, src1, src1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniDatatoFp32Part0_4x4); \
    VXC_DP4x4(vecB, src1, src1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniDatatoFp32Part1_4x4); \
    vecA = vecA * input_scale + input_tail; \
    vecB = vecB * input_scale + input_tail; \
    vecA = funcName##_(vecA); \
    vecB = funcName##_(vecB); \
    vecA = vecA * output_scale + output_zp; \
    vecB = vecB * output_scale + output_zp; \
 \
    convert_type dst0, dst1; \
    _viv_asm(CONV_RTE, dst0, vecA); \
    _viv_asm(CONV_RTE, dst1, vecB); \
    dst_type dst2; \
    VXC_DP2x8(dst2, dst0, dst1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 1), uniExtract8Data_2x8); \
    dst_copy_type dst; \
    _viv_asm(COPY, dst, dst2, 16); \
    VXC_WriteImage2DArray(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}

//SIGMOID
TENSOR_TRANSCENDENTAL(sigmoid, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(sigmoid, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(sigmoid, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(sigmoid, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(sigmoid, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(sigmoid, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(sigmoid, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(sigmoid, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(sigmoid, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(sigmoid, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//SQRT
TENSOR_TRANSCENDENTAL(sqrt, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(sqrt, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(sqrt, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(sqrt, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(sqrt, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(sqrt, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(sqrt, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(sqrt, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(sqrt, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(sqrt, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//RSQRT
TENSOR_TRANSCENDENTAL(rsqrt, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(rsqrt, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(rsqrt, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(rsqrt, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(rsqrt, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(rsqrt, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(rsqrt, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(rsqrt, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(rsqrt, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(rsqrt, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//TANH
TENSOR_TRANSCENDENTAL(tanh, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(tanh, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(tanh, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(tanh, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(tanh, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(tanh, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(tanh, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(tanh, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(tanh, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(tanh, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//SOFTRELU
TENSOR_TRANSCENDENTAL(softRelu, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(softRelu, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(softRelu, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(softRelu, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(softRelu, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(softRelu, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(softRelu, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(softRelu, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(softRelu, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(softRelu, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//SQUARE
TENSOR_TRANSCENDENTAL(square, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(square, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(square, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(square, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(square, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL(square, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(square, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL(square, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL(square, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL(square, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)

#define TENSOR_TRANSCENDENTAL_2D(funcName, src_type_name, dst_type_name, src_type, src_copy_type, convert_type, dst_type, dst_copy_type) \
    __kernel void activation_##funcName##_##src_type_name##to##dst_type_name##_2D( \
    __read_only  image2d_array_t  input, \
    __write_only image2d_array_t  output \
    ) \
{ \
    int2 coord = (int2)(get_global_id(0), get_global_id(1)); \
    src_type      src0; \
    src_copy_type src1; \
    VXC_ReadImage(src0, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    _viv_asm(COPY, src1, src0, 16); \
 \
    float4 vecA; \
    float4 vecB; \
    VXC_DP4x4(vecA, src1, src1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniDatatoFp32Part0_4x4); \
    VXC_DP4x4(vecB, src1, src1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniDatatoFp32Part1_4x4); \
    vecA = vecA * input_scale + input_tail; \
    vecB = vecB * input_scale + input_tail; \
    vecA = funcName##_(vecA); \
    vecB = funcName##_(vecB); \
    vecA = vecA * output_scale + output_zp; \
    vecB = vecB * output_scale + output_zp; \
 \
    convert_type dst0, dst1; \
    _viv_asm(CONV_RTE, dst0, vecA); \
    _viv_asm(CONV_RTE, dst1, vecB); \
    dst_type dst2; \
    VXC_DP2x8(dst2, dst0, dst1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 1), uniExtract8Data_2x8); \
    dst_copy_type dst; \
    _viv_asm(COPY, dst, dst2, 16); \
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}

//SIGMOID
TENSOR_TRANSCENDENTAL_2D(sigmoid, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sigmoid, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//SQRT
TENSOR_TRANSCENDENTAL_2D(sqrt, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sqrt, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(sqrt, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(sqrt, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sqrt, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(sqrt, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sqrt, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(sqrt, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sqrt, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(sqrt, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//RSQRT
TENSOR_TRANSCENDENTAL_2D(rsqrt, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(rsqrt, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//TANH
TENSOR_TRANSCENDENTAL_2D(tanh, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(tanh, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(tanh, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(tanh, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(tanh, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(tanh, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(tanh, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(tanh, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(tanh, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(tanh, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//SOFTRELU
TENSOR_TRANSCENDENTAL_2D(softRelu, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(softRelu, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(softRelu, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(softRelu, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(softRelu, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(softRelu, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(softRelu, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(softRelu, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(softRelu, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(softRelu, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)
//SQUARE
TENSOR_TRANSCENDENTAL_2D(square, F16, F16, vxc_short8, vxc_half8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(square, F16, I8,  vxc_short8, vxc_half8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(square, F16, U8,  vxc_short8, vxc_half8,  int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(square, F16, I16, vxc_short8, vxc_half8,  int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(square, I8,  I8,  vxc_char8,  vxc_char8,  int4,  vxc_char8,  vxc_char8)
TENSOR_TRANSCENDENTAL_2D(square, I8,  F16, vxc_char8,  vxc_char8,  half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(square, U8,  U8,  vxc_uchar8, vxc_uchar8, int4,  vxc_uchar8, vxc_uchar8)
TENSOR_TRANSCENDENTAL_2D(square, U8,  F16, vxc_uchar8, vxc_uchar8, half4, vxc_half8,  vxc_short8)
TENSOR_TRANSCENDENTAL_2D(square, I16, I16, vxc_short8, vxc_short8, int4,  vxc_short8, vxc_short8)
TENSOR_TRANSCENDENTAL_2D(square, I16, F16, vxc_short8, vxc_short8, half4, vxc_half8,  vxc_short8)

_viv_uniform VXC_512Bits uniConvBF16toF32_Part0_2x8;
_viv_uniform VXC_512Bits uniConvBF16toF32_Part1_2x8;
_viv_uniform VXC_512Bits uniExtractOddData_2x8;
#define TENSOR_TRANSCENDENTAL_BF16(funcName) \
__kernel void activation_##funcName##_BF16toBF16( \
    __read_only  image2d_array_t  input, \
    __write_only image2d_array_t  output \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0); \
    vxc_ushort8   src0, src1, dst; \
    VXC_ReadImage2DArray(src0, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
 \
    float4 vecA; \
    float4 vecB; \
    vxc_short8 zero = (vxc_short8)(0, 0, 0, 0, 0, 0, 0, 0); \
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part0_2x8); \
    _viv_asm(COPY, vecA, src1, 16); \
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part1_2x8); \
    _viv_asm(COPY, vecB, src1, 16); \
    vecA = funcName##_(vecA); \
    vecB = funcName##_(vecB); \
 \
    _viv_asm(COPY, src0, vecA, 16); \
    _viv_asm(COPY, src1, vecB, 16); \
 \
    VXC_DP2x8(dst, src0, src1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniExtractOddData_2x8); \
    VXC_WriteImage2DArray(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}

//SIGMOID
TENSOR_TRANSCENDENTAL_BF16(sigmoid)
//SQRT
TENSOR_TRANSCENDENTAL_BF16(sqrt)
//RSQRT
TENSOR_TRANSCENDENTAL_BF16(rsqrt)
//TANH
TENSOR_TRANSCENDENTAL_BF16(tanh)
//SOFTRELU
TENSOR_TRANSCENDENTAL_BF16(softRelu)
//SQUARE
TENSOR_TRANSCENDENTAL_BF16(square)

#define TENSOR_TRANSCENDENTAL_BF16_2D(funcName) \
    __kernel void activation_##funcName##_BF16toBF16_2D( \
    __read_only  image2d_array_t  input, \
    __write_only image2d_array_t  output \
    ) \
{ \
    int2 coord = (int2)(get_global_id(0), get_global_id(1)); \
    vxc_ushort8   src0, src1, dst; \
    VXC_ReadImage(src0, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
 \
    float4 vecA; \
    float4 vecB; \
    vxc_short8 zero = (vxc_short8)(0, 0, 0, 0, 0, 0, 0, 0); \
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part0_2x8); \
    _viv_asm(COPY, vecA, src1, 16); \
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part1_2x8); \
    _viv_asm(COPY, vecB, src1, 16); \
    vecA = funcName##_(vecA); \
    vecB = funcName##_(vecB); \
 \
    _viv_asm(COPY, src0, vecA, 16); \
    _viv_asm(COPY, src1, vecB, 16); \
 \
    VXC_DP2x8(dst, src0, src1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniExtractOddData_2x8); \
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}

//SIGMOID
TENSOR_TRANSCENDENTAL_BF16_2D(sigmoid)
//SQRT
TENSOR_TRANSCENDENTAL_BF16_2D(sqrt)
//RSQRT
TENSOR_TRANSCENDENTAL_BF16_2D(rsqrt)
//TANH
TENSOR_TRANSCENDENTAL_BF16_2D(tanh)
//SOFTRELU
TENSOR_TRANSCENDENTAL_BF16_2D(softRelu)
//SQUARE
TENSOR_TRANSCENDENTAL_BF16_2D(square)

#define TENSOR_TRANSCENDENTAL_F32TOBF16(funcName) \
    __kernel void activation_##funcName##_F32toBF16( \
    __read_only  image2d_array_t  input, \
    __write_only image2d_array_t  output \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0); \
    int4 coord_in = coord; \
    vxc_ushort8   src0, src1, dst; \
    float4 vecA; \
    float4 vecB; \
    vxc_ushort8 w0, w1; \
    coord_in.x <<= 1; \
    VXC_ReadImage2DArray(w0, input, coord_in, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    VXC_ReadImage2DArray(w1, input, coord_in, VXC_5BITOFFSET_XY(8, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    _viv_asm(COPY, vecA, w0, 16); \
    _viv_asm(COPY, vecB, w1, 16); \
 \
    vecA = funcName##_(vecA); \
    vecB = funcName##_(vecB); \
 \
    _viv_asm(COPY, src0, vecA, 16); \
    _viv_asm(COPY, src1, vecB, 16); \
 \
    VXC_DP2x8(dst, src0, src1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniExtractOddData_2x8); \
    VXC_WriteImage2DArray(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}


//SIGMOID
TENSOR_TRANSCENDENTAL_F32TOBF16(sigmoid)
//SQRT
TENSOR_TRANSCENDENTAL_F32TOBF16(sqrt)
//RSQRT
TENSOR_TRANSCENDENTAL_F32TOBF16(rsqrt)
//TANH
TENSOR_TRANSCENDENTAL_F32TOBF16(tanh)
//SOFTRELU
TENSOR_TRANSCENDENTAL_F32TOBF16(softRelu)
//SQUARE
TENSOR_TRANSCENDENTAL_F32TOBF16(square)

#define TENSOR_TRANSCENDENTAL_F32TOBF16_2D(funcName) \
    __kernel void activation_##funcName##_F32toBF16_2D( \
    __read_only  image2d_t  input, \
    __write_only image2d_t  output \
    ) \
{ \
    int2 coord = (int2)(get_global_id(0), get_global_id(1)); \
    vxc_ushort8   src0, src1, dst; \
    float4 vecA; \
    float4 vecB; \
    vxc_ushort8 w0, w1; \
    int2 coord_in = coord; \
    coord_in.x <<= 1; \
    VXC_ReadImage(w0, input, coord_in, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    VXC_ReadImage(w1, input, coord_in, VXC_5BITOFFSET_XY(8, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    _viv_asm(COPY, vecA, w0, 16); \
    _viv_asm(COPY, vecB, w1, 16); \
    vecA = funcName##_(vecA); \
    vecB = funcName##_(vecB); \
 \
    _viv_asm(COPY, src0, vecA, 16); \
    _viv_asm(COPY, src1, vecB, 16); \
 \
    VXC_DP2x8(dst, src0, src1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniExtractOddData_2x8); \
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}

//SIGMOID
TENSOR_TRANSCENDENTAL_F32TOBF16_2D(sigmoid)
//SQRT
TENSOR_TRANSCENDENTAL_F32TOBF16_2D(sqrt)
//RSQRT
TENSOR_TRANSCENDENTAL_F32TOBF16_2D(rsqrt)
//TANH
TENSOR_TRANSCENDENTAL_F32TOBF16_2D(tanh)
//SOFTRELU
TENSOR_TRANSCENDENTAL_F32TOBF16_2D(softRelu)
//SQUARE
TENSOR_TRANSCENDENTAL_F32TOBF16_2D(square)

_viv_uniform VXC_512Bits uniI16TimesI16toF16_2x8;
__kernel void activation_square_I16toF16_2D_opt
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output
    )
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));
    vxc_short8 src;
    vxc_half8 dst;
    VXC_ReadImage(src, input, coord, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));

    VXC_DP2x8(dst, src, src, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniI16TimesI16toF16_2x8);
    _viv_asm(COPY, src, dst, 16);
    VXC_WriteImage(output, coord, src, VXC_MODIFIER(0, 7, 0,VXC_RM_TowardZero, 0));
}

__kernel void activation_square_I16toF16_opt
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0);
    vxc_short8 src;
    vxc_half8 dst;
    VXC_ReadImage2DArray(src, input, coord, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));

    VXC_DP2x8(dst, src, src, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniI16TimesI16toF16_2x8);
    _viv_asm(COPY, src, dst, 16);
    VXC_WriteImage2DArray(output, coord, src, VXC_MODIFIER(0, 7, 0,VXC_RM_TowardZero, 0));
}

__kernel void activation_square_I16toI16_2D_opt
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output
    )
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));
    vxc_short8 src;
    VXC_ReadImage(src, input, coord, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));

    VXC_DP2x8(src, src, src, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniI16TimesI16toF16_2x8);
    VXC_WriteImage(output, coord, src, VXC_MODIFIER(0, 7, 0,VXC_RM_TowardZero, 0));
}

__kernel void activation_square_I16toI16_opt
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0);
    vxc_short8 src;
    VXC_ReadImage2DArray(src, input, coord, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));

    VXC_DP2x8(src, src, src, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniI16TimesI16toF16_2x8);
    VXC_WriteImage2DArray(output, coord, src, VXC_MODIFIER(0, 7, 0,VXC_RM_TowardZero, 0));
}
