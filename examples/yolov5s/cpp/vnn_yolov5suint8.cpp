/****************************************************************************
*   Generated by ACUITY 6.12.4
*   Match ovxlib 1.1.53
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_yolov5suint8.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        if( NULL == _node ) {\
            goto error;\
        }\
        _node->uid = (uint32_t)_uid;\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(vsi_size_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        if ( enable_from_handle )\
        {\
            _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        else\
        {\
            _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR_FROM_HANDLE(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (142)
#define NET_NORM_TENSOR_NUM     (4)
#define NET_CONST_TENSOR_NUM    (120)
#define NET_VIRTUAL_TENSOR_NUM  (142)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    int32_t ret;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = VSI_FSEEK(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    ret = fread(data, 1, sz, fp);
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateYolov5sUint8
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx,
    const vsi_nn_preprocess_map_element_t * pre_process_map,
    uint32_t pre_process_map_count,
    const vsi_nn_postprocess_map_element_t * post_process_map,
    uint32_t post_process_map_count
    )
{
    uint32_t                _infinity = VSI_NN_FLOAT32_INF;
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;
    uint32_t                i = 0;
    char *                  use_img_process_s;
    char *                  use_from_handle = NULL;
    int32_t                 enable_pre_post_process = 0;
    int32_t                 enable_from_handle = 0;
    vsi_bool                sort = FALSE;
    vsi_bool                inference_with_nbg = FALSE;
    char*                   pos = NULL;





    (void)(_infinity);
    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;
    memset( &attr, 0, sizeof( attr ) );
    memset( &node, 0, sizeof( vsi_nn_node_t * ) * NET_NODE_NUM );

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    pos = strstr(data_file_name, ".nb");
    if( pos && strcmp(pos, ".nb") == 0 )
    {
        inference_with_nbg = TRUE;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
    }
    else
    {
        ctx = in_ctx;
    }

    use_img_process_s = getenv( "VSI_USE_IMAGE_PROCESS" );
    if( use_img_process_s )
    {
        enable_pre_post_process = atoi(use_img_process_s);
    }
    use_from_handle = getenv( "VSI_USE_FROM_HANDLE" );
    if ( use_from_handle )
    {
        enable_from_handle = atoi(use_from_handle);
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphVersion( graph, VNN_VERSION_MAJOR, VNN_VERSION_MINOR, VNN_VERSION_PATCH );
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 3 );

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/
    if( !inference_with_nbg )
    {

    /*-----------------------------------------
      lid       - Conv_Conv_0_190
      var       - node[0]
      name      - Conv_Conv_0
      operation - convolution
      input     - [640, 640, 3, 1]
      filter    - [6, 6, 3, 32]
      output    - [320, 320, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_CONV2D, 3, 1, 190);
    node[0]->nn_param.conv2d.ksize[0] = 6;
    node[0]->nn_param.conv2d.ksize[1] = 6;
    node[0]->nn_param.conv2d.weights = 32;
    node[0]->nn_param.conv2d.stride[0] = 2;
    node[0]->nn_param.conv2d.stride[1] = 2;
    node[0]->nn_param.conv2d.pad[0] = 2;
    node[0]->nn_param.conv2d.pad[1] = 2;
    node[0]->nn_param.conv2d.pad[2] = 2;
    node[0]->nn_param.conv2d.pad[3] = 2;
    node[0]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[0]->nn_param.conv2d.group = 1;
    node[0]->nn_param.conv2d.dilation[0] = 1;
    node[0]->nn_param.conv2d.dilation[1] = 1;
    node[0]->nn_param.conv2d.multiplier = 0;
    node[0]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[0]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[0]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_1_191_Mul_Mul_2_175
      var       - node[1]
      name      - swish
      operation - swish
      input     - [320, 320, 32, 1]
      output    - [320, 320, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_SWISH, 1, 1, 175);
    node[1]->nn_param.swish.type = VSI_NN_SWISH;
    node[1]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_3_174
      var       - node[2]
      name      - Conv_Conv_3
      operation - convolution
      input     - [320, 320, 32, 1]
      filter    - [3, 3, 32, 64]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_CONV2D, 3, 1, 174);
    node[2]->nn_param.conv2d.ksize[0] = 3;
    node[2]->nn_param.conv2d.ksize[1] = 3;
    node[2]->nn_param.conv2d.weights = 64;
    node[2]->nn_param.conv2d.stride[0] = 2;
    node[2]->nn_param.conv2d.stride[1] = 2;
    node[2]->nn_param.conv2d.pad[0] = 1;
    node[2]->nn_param.conv2d.pad[1] = 1;
    node[2]->nn_param.conv2d.pad[2] = 1;
    node[2]->nn_param.conv2d.pad[3] = 1;
    node[2]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[2]->nn_param.conv2d.group = 1;
    node[2]->nn_param.conv2d.dilation[0] = 1;
    node[2]->nn_param.conv2d.dilation[1] = 1;
    node[2]->nn_param.conv2d.multiplier = 0;
    node[2]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[2]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_4_160_Mul_Mul_5_159
      var       - node[3]
      name      - swish
      operation - swish
      input     - [160, 160, 64, 1]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_SWISH, 1, 1, 159);
    node[3]->nn_param.swish.type = VSI_NN_SWISH;
    node[3]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_16_145
      var       - node[4]
      name      - Conv_Conv_16
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [1, 1, 64, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_CONV2D, 3, 1, 145);
    node[4]->nn_param.conv2d.ksize[0] = 1;
    node[4]->nn_param.conv2d.ksize[1] = 1;
    node[4]->nn_param.conv2d.weights = 32;
    node[4]->nn_param.conv2d.stride[0] = 1;
    node[4]->nn_param.conv2d.stride[1] = 1;
    node[4]->nn_param.conv2d.pad[0] = 0;
    node[4]->nn_param.conv2d.pad[1] = 0;
    node[4]->nn_param.conv2d.pad[2] = 0;
    node[4]->nn_param.conv2d.pad[3] = 0;
    node[4]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[4]->nn_param.conv2d.group = 1;
    node[4]->nn_param.conv2d.dilation[0] = 1;
    node[4]->nn_param.conv2d.dilation[1] = 1;
    node[4]->nn_param.conv2d.multiplier = 0;
    node[4]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[4]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[4]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_6_170
      var       - node[5]
      name      - Conv_Conv_6
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [1, 1, 64, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_CONV2D, 3, 1, 170);
    node[5]->nn_param.conv2d.ksize[0] = 1;
    node[5]->nn_param.conv2d.ksize[1] = 1;
    node[5]->nn_param.conv2d.weights = 32;
    node[5]->nn_param.conv2d.stride[0] = 1;
    node[5]->nn_param.conv2d.stride[1] = 1;
    node[5]->nn_param.conv2d.pad[0] = 0;
    node[5]->nn_param.conv2d.pad[1] = 0;
    node[5]->nn_param.conv2d.pad[2] = 0;
    node[5]->nn_param.conv2d.pad[3] = 0;
    node[5]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[5]->nn_param.conv2d.group = 1;
    node[5]->nn_param.conv2d.dilation[0] = 1;
    node[5]->nn_param.conv2d.dilation[1] = 1;
    node[5]->nn_param.conv2d.multiplier = 0;
    node[5]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[5]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[5]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_17_146_Mul_Mul_18_132
      var       - node[6]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_SWISH, 1, 1, 132);
    node[6]->nn_param.swish.type = VSI_NN_SWISH;
    node[6]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_7_171_Mul_Mul_8_157
      var       - node[7]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_SWISH, 1, 1, 157);
    node[7]->nn_param.swish.type = VSI_NN_SWISH;
    node[7]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_9_192
      var       - node[8]
      name      - Conv_Conv_9
      operation - convolution
      input     - [160, 160, 32, 1]
      filter    - [1, 1, 32, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_CONV2D, 3, 1, 192);
    node[8]->nn_param.conv2d.ksize[0] = 1;
    node[8]->nn_param.conv2d.ksize[1] = 1;
    node[8]->nn_param.conv2d.weights = 32;
    node[8]->nn_param.conv2d.stride[0] = 1;
    node[8]->nn_param.conv2d.stride[1] = 1;
    node[8]->nn_param.conv2d.pad[0] = 0;
    node[8]->nn_param.conv2d.pad[1] = 0;
    node[8]->nn_param.conv2d.pad[2] = 0;
    node[8]->nn_param.conv2d.pad[3] = 0;
    node[8]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[8]->nn_param.conv2d.group = 1;
    node[8]->nn_param.conv2d.dilation[0] = 1;
    node[8]->nn_param.conv2d.dilation[1] = 1;
    node[8]->nn_param.conv2d.multiplier = 0;
    node[8]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[8]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[8]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_10_189_Mul_Mul_11_188
      var       - node[9]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_SWISH, 1, 1, 188);
    node[9]->nn_param.swish.type = VSI_NN_SWISH;
    node[9]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_12_172
      var       - node[10]
      name      - Conv_Conv_12
      operation - convolution
      input     - [160, 160, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_CONV2D, 3, 1, 172);
    node[10]->nn_param.conv2d.ksize[0] = 3;
    node[10]->nn_param.conv2d.ksize[1] = 3;
    node[10]->nn_param.conv2d.weights = 32;
    node[10]->nn_param.conv2d.stride[0] = 1;
    node[10]->nn_param.conv2d.stride[1] = 1;
    node[10]->nn_param.conv2d.pad[0] = 1;
    node[10]->nn_param.conv2d.pad[1] = 1;
    node[10]->nn_param.conv2d.pad[2] = 1;
    node[10]->nn_param.conv2d.pad[3] = 1;
    node[10]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[10]->nn_param.conv2d.group = 1;
    node[10]->nn_param.conv2d.dilation[0] = 1;
    node[10]->nn_param.conv2d.dilation[1] = 1;
    node[10]->nn_param.conv2d.multiplier = 0;
    node[10]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[10]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[10]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_13_173_Mul_Mul_14_158
      var       - node[11]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_SWISH, 1, 1, 158);
    node[11]->nn_param.swish.type = VSI_NN_SWISH;
    node[11]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Add_Add_15_144
      var       - node[12]
      name      - Add_Add_15
      operation - add
      input     - [160, 160, 32, 1]
                  [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_ADD, 2, 1, 144);

    /*-----------------------------------------
      lid       - Concat_Concat_19_131
      var       - node[13]
      name      - Concat_Concat_19
      operation - concat
      input     - [160, 160, 32, 1]
                  [160, 160, 32, 1]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_CONCAT, 2, 1, 131);
    node[13]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_20_116
      var       - node[14]
      name      - Conv_Conv_20
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_CONV2D, 3, 1, 116);
    node[14]->nn_param.conv2d.ksize[0] = 1;
    node[14]->nn_param.conv2d.ksize[1] = 1;
    node[14]->nn_param.conv2d.weights = 64;
    node[14]->nn_param.conv2d.stride[0] = 1;
    node[14]->nn_param.conv2d.stride[1] = 1;
    node[14]->nn_param.conv2d.pad[0] = 0;
    node[14]->nn_param.conv2d.pad[1] = 0;
    node[14]->nn_param.conv2d.pad[2] = 0;
    node[14]->nn_param.conv2d.pad[3] = 0;
    node[14]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[14]->nn_param.conv2d.group = 1;
    node[14]->nn_param.conv2d.dilation[0] = 1;
    node[14]->nn_param.conv2d.dilation[1] = 1;
    node[14]->nn_param.conv2d.multiplier = 0;
    node[14]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[14]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[14]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_21_117_Mul_Mul_22_106
      var       - node[15]
      name      - swish
      operation - swish
      input     - [160, 160, 64, 1]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_SWISH, 1, 1, 106);
    node[15]->nn_param.swish.type = VSI_NN_SWISH;
    node[15]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_23_104
      var       - node[16]
      name      - Conv_Conv_23
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [3, 3, 64, 128]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_CONV2D, 3, 1, 104);
    node[16]->nn_param.conv2d.ksize[0] = 3;
    node[16]->nn_param.conv2d.ksize[1] = 3;
    node[16]->nn_param.conv2d.weights = 128;
    node[16]->nn_param.conv2d.stride[0] = 2;
    node[16]->nn_param.conv2d.stride[1] = 2;
    node[16]->nn_param.conv2d.pad[0] = 1;
    node[16]->nn_param.conv2d.pad[1] = 1;
    node[16]->nn_param.conv2d.pad[2] = 1;
    node[16]->nn_param.conv2d.pad[3] = 1;
    node[16]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[16]->nn_param.conv2d.group = 1;
    node[16]->nn_param.conv2d.dilation[0] = 1;
    node[16]->nn_param.conv2d.dilation[1] = 1;
    node[16]->nn_param.conv2d.multiplier = 0;
    node[16]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[16]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[16]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_24_105_Mul_Mul_25_93
      var       - node[17]
      name      - swish
      operation - swish
      input     - [80, 80, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_SWISH, 1, 1, 93);
    node[17]->nn_param.swish.type = VSI_NN_SWISH;
    node[17]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_43_80
      var       - node[18]
      name      - Conv_Conv_43
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_CONV2D, 3, 1, 80);
    node[18]->nn_param.conv2d.ksize[0] = 1;
    node[18]->nn_param.conv2d.ksize[1] = 1;
    node[18]->nn_param.conv2d.weights = 64;
    node[18]->nn_param.conv2d.stride[0] = 1;
    node[18]->nn_param.conv2d.stride[1] = 1;
    node[18]->nn_param.conv2d.pad[0] = 0;
    node[18]->nn_param.conv2d.pad[1] = 0;
    node[18]->nn_param.conv2d.pad[2] = 0;
    node[18]->nn_param.conv2d.pad[3] = 0;
    node[18]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[18]->nn_param.conv2d.group = 1;
    node[18]->nn_param.conv2d.dilation[0] = 1;
    node[18]->nn_param.conv2d.dilation[1] = 1;
    node[18]->nn_param.conv2d.multiplier = 0;
    node[18]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[18]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[18]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_26_125
      var       - node[19]
      name      - Conv_Conv_26
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_CONV2D, 3, 1, 125);
    node[19]->nn_param.conv2d.ksize[0] = 1;
    node[19]->nn_param.conv2d.ksize[1] = 1;
    node[19]->nn_param.conv2d.weights = 64;
    node[19]->nn_param.conv2d.stride[0] = 1;
    node[19]->nn_param.conv2d.stride[1] = 1;
    node[19]->nn_param.conv2d.pad[0] = 0;
    node[19]->nn_param.conv2d.pad[1] = 0;
    node[19]->nn_param.conv2d.pad[2] = 0;
    node[19]->nn_param.conv2d.pad[3] = 0;
    node[19]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[19]->nn_param.conv2d.group = 1;
    node[19]->nn_param.conv2d.dilation[0] = 1;
    node[19]->nn_param.conv2d.dilation[1] = 1;
    node[19]->nn_param.conv2d.multiplier = 0;
    node[19]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[19]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[19]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_44_79_Mul_Mul_45_76
      var       - node[20]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_SWISH, 1, 1, 76);
    node[20]->nn_param.swish.type = VSI_NN_SWISH;
    node[20]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_27_126_Mul_Mul_28_112
      var       - node[21]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_SWISH, 1, 1, 112);
    node[21]->nn_param.swish.type = VSI_NN_SWISH;
    node[21]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_29_142
      var       - node[22]
      name      - Conv_Conv_29
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV2D, 3, 1, 142);
    node[22]->nn_param.conv2d.ksize[0] = 1;
    node[22]->nn_param.conv2d.ksize[1] = 1;
    node[22]->nn_param.conv2d.weights = 64;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 0;
    node[22]->nn_param.conv2d.pad[1] = 0;
    node[22]->nn_param.conv2d.pad[2] = 0;
    node[22]->nn_param.conv2d.pad[3] = 0;
    node[22]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[22]->nn_param.conv2d.group = 1;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->nn_param.conv2d.multiplier = 0;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_30_143_Mul_Mul_31_130
      var       - node[23]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_SWISH, 1, 1, 130);
    node[23]->nn_param.swish.type = VSI_NN_SWISH;
    node[23]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_32_127
      var       - node[24]
      name      - Conv_Conv_32
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_CONV2D, 3, 1, 127);
    node[24]->nn_param.conv2d.ksize[0] = 3;
    node[24]->nn_param.conv2d.ksize[1] = 3;
    node[24]->nn_param.conv2d.weights = 64;
    node[24]->nn_param.conv2d.stride[0] = 1;
    node[24]->nn_param.conv2d.stride[1] = 1;
    node[24]->nn_param.conv2d.pad[0] = 1;
    node[24]->nn_param.conv2d.pad[1] = 1;
    node[24]->nn_param.conv2d.pad[2] = 1;
    node[24]->nn_param.conv2d.pad[3] = 1;
    node[24]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[24]->nn_param.conv2d.group = 1;
    node[24]->nn_param.conv2d.dilation[0] = 1;
    node[24]->nn_param.conv2d.dilation[1] = 1;
    node[24]->nn_param.conv2d.multiplier = 0;
    node[24]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[24]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[24]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_33_128_Mul_Mul_34_113
      var       - node[25]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_SWISH, 1, 1, 113);
    node[25]->nn_param.swish.type = VSI_NN_SWISH;
    node[25]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Add_Add_35_101
      var       - node[26]
      name      - Add_Add_35
      operation - add
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_ADD, 2, 1, 101);

    /*-----------------------------------------
      lid       - Conv_Conv_36_129
      var       - node[27]
      name      - Conv_Conv_36
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV2D, 3, 1, 129);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 64;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->nn_param.conv2d.multiplier = 0;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_37_115_Mul_Mul_38_114
      var       - node[28]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_SWISH, 1, 1, 114);
    node[28]->nn_param.swish.type = VSI_NN_SWISH;
    node[28]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_39_102
      var       - node[29]
      name      - Conv_Conv_39
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_CONV2D, 3, 1, 102);
    node[29]->nn_param.conv2d.ksize[0] = 3;
    node[29]->nn_param.conv2d.ksize[1] = 3;
    node[29]->nn_param.conv2d.weights = 64;
    node[29]->nn_param.conv2d.stride[0] = 1;
    node[29]->nn_param.conv2d.stride[1] = 1;
    node[29]->nn_param.conv2d.pad[0] = 1;
    node[29]->nn_param.conv2d.pad[1] = 1;
    node[29]->nn_param.conv2d.pad[2] = 1;
    node[29]->nn_param.conv2d.pad[3] = 1;
    node[29]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[29]->nn_param.conv2d.group = 1;
    node[29]->nn_param.conv2d.dilation[0] = 1;
    node[29]->nn_param.conv2d.dilation[1] = 1;
    node[29]->nn_param.conv2d.multiplier = 0;
    node[29]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[29]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[29]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_40_103_Mul_Mul_41_92
      var       - node[30]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_SWISH, 1, 1, 92);
    node[30]->nn_param.swish.type = VSI_NN_SWISH;
    node[30]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Add_Add_42_91
      var       - node[31]
      name      - Add_Add_42
      operation - add
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_ADD, 2, 1, 91);

    /*-----------------------------------------
      lid       - Concat_Concat_46_75
      var       - node[32]
      name      - Concat_Concat_46
      operation - concat
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_CONCAT, 2, 1, 75);
    node[32]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_47_58
      var       - node[33]
      name      - Conv_Conv_47
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_CONV2D, 3, 1, 58);
    node[33]->nn_param.conv2d.ksize[0] = 1;
    node[33]->nn_param.conv2d.ksize[1] = 1;
    node[33]->nn_param.conv2d.weights = 128;
    node[33]->nn_param.conv2d.stride[0] = 1;
    node[33]->nn_param.conv2d.stride[1] = 1;
    node[33]->nn_param.conv2d.pad[0] = 0;
    node[33]->nn_param.conv2d.pad[1] = 0;
    node[33]->nn_param.conv2d.pad[2] = 0;
    node[33]->nn_param.conv2d.pad[3] = 0;
    node[33]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[33]->nn_param.conv2d.group = 1;
    node[33]->nn_param.conv2d.dilation[0] = 1;
    node[33]->nn_param.conv2d.dilation[1] = 1;
    node[33]->nn_param.conv2d.multiplier = 0;
    node[33]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[33]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[33]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_48_59_Mul_Mul_49_44
      var       - node[34]
      name      - swish
      operation - swish
      input     - [80, 80, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_SWISH, 1, 1, 44);
    node[34]->nn_param.swish.type = VSI_NN_SWISH;
    node[34]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_50_156
      var       - node[35]
      name      - Conv_Conv_50
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [3, 3, 128, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_CONV2D, 3, 1, 156);
    node[35]->nn_param.conv2d.ksize[0] = 3;
    node[35]->nn_param.conv2d.ksize[1] = 3;
    node[35]->nn_param.conv2d.weights = 256;
    node[35]->nn_param.conv2d.stride[0] = 2;
    node[35]->nn_param.conv2d.stride[1] = 2;
    node[35]->nn_param.conv2d.pad[0] = 1;
    node[35]->nn_param.conv2d.pad[1] = 1;
    node[35]->nn_param.conv2d.pad[2] = 1;
    node[35]->nn_param.conv2d.pad[3] = 1;
    node[35]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[35]->nn_param.conv2d.group = 1;
    node[35]->nn_param.conv2d.dilation[0] = 1;
    node[35]->nn_param.conv2d.dilation[1] = 1;
    node[35]->nn_param.conv2d.multiplier = 0;
    node[35]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[35]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[35]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_51_155_Mul_Mul_52_154
      var       - node[36]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_SWISH, 1, 1, 154);
    node[36]->nn_param.swish.type = VSI_NN_SWISH;
    node[36]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_77_141
      var       - node[37]
      name      - Conv_Conv_77
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_CONV2D, 3, 1, 141);
    node[37]->nn_param.conv2d.ksize[0] = 1;
    node[37]->nn_param.conv2d.ksize[1] = 1;
    node[37]->nn_param.conv2d.weights = 128;
    node[37]->nn_param.conv2d.stride[0] = 1;
    node[37]->nn_param.conv2d.stride[1] = 1;
    node[37]->nn_param.conv2d.pad[0] = 0;
    node[37]->nn_param.conv2d.pad[1] = 0;
    node[37]->nn_param.conv2d.pad[2] = 0;
    node[37]->nn_param.conv2d.pad[3] = 0;
    node[37]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[37]->nn_param.conv2d.group = 1;
    node[37]->nn_param.conv2d.dilation[0] = 1;
    node[37]->nn_param.conv2d.dilation[1] = 1;
    node[37]->nn_param.conv2d.multiplier = 0;
    node[37]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[37]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[37]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_53_201
      var       - node[38]
      name      - Conv_Conv_53
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_CONV2D, 3, 1, 201);
    node[38]->nn_param.conv2d.ksize[0] = 1;
    node[38]->nn_param.conv2d.ksize[1] = 1;
    node[38]->nn_param.conv2d.weights = 128;
    node[38]->nn_param.conv2d.stride[0] = 1;
    node[38]->nn_param.conv2d.stride[1] = 1;
    node[38]->nn_param.conv2d.pad[0] = 0;
    node[38]->nn_param.conv2d.pad[1] = 0;
    node[38]->nn_param.conv2d.pad[2] = 0;
    node[38]->nn_param.conv2d.pad[3] = 0;
    node[38]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[38]->nn_param.conv2d.group = 1;
    node[38]->nn_param.conv2d.dilation[0] = 1;
    node[38]->nn_param.conv2d.dilation[1] = 1;
    node[38]->nn_param.conv2d.multiplier = 0;
    node[38]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[38]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[38]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_78_140_Mul_Mul_79_139
      var       - node[39]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_SWISH, 1, 1, 139);
    node[39]->nn_param.swish.type = VSI_NN_SWISH;
    node[39]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_54_202_Mul_Mul_55_196
      var       - node[40]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_SWISH, 1, 1, 196);
    node[40]->nn_param.swish.type = VSI_NN_SWISH;
    node[40]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_56_204
      var       - node[41]
      name      - Conv_Conv_56
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_CONV2D, 3, 1, 204);
    node[41]->nn_param.conv2d.ksize[0] = 1;
    node[41]->nn_param.conv2d.ksize[1] = 1;
    node[41]->nn_param.conv2d.weights = 128;
    node[41]->nn_param.conv2d.stride[0] = 1;
    node[41]->nn_param.conv2d.stride[1] = 1;
    node[41]->nn_param.conv2d.pad[0] = 0;
    node[41]->nn_param.conv2d.pad[1] = 0;
    node[41]->nn_param.conv2d.pad[2] = 0;
    node[41]->nn_param.conv2d.pad[3] = 0;
    node[41]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[41]->nn_param.conv2d.group = 1;
    node[41]->nn_param.conv2d.dilation[0] = 1;
    node[41]->nn_param.conv2d.dilation[1] = 1;
    node[41]->nn_param.conv2d.multiplier = 0;
    node[41]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[41]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[41]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_57_203_Mul_Mul_58_200
      var       - node[42]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_SWISH, 1, 1, 200);
    node[42]->nn_param.swish.type = VSI_NN_SWISH;
    node[42]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_59_199
      var       - node[43]
      name      - Conv_Conv_59
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[43], VSI_NN_OP_CONV2D, 3, 1, 199);
    node[43]->nn_param.conv2d.ksize[0] = 3;
    node[43]->nn_param.conv2d.ksize[1] = 3;
    node[43]->nn_param.conv2d.weights = 128;
    node[43]->nn_param.conv2d.stride[0] = 1;
    node[43]->nn_param.conv2d.stride[1] = 1;
    node[43]->nn_param.conv2d.pad[0] = 1;
    node[43]->nn_param.conv2d.pad[1] = 1;
    node[43]->nn_param.conv2d.pad[2] = 1;
    node[43]->nn_param.conv2d.pad[3] = 1;
    node[43]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[43]->nn_param.conv2d.group = 1;
    node[43]->nn_param.conv2d.dilation[0] = 1;
    node[43]->nn_param.conv2d.dilation[1] = 1;
    node[43]->nn_param.conv2d.multiplier = 0;
    node[43]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[43]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[43]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_60_198_Mul_Mul_61_197
      var       - node[44]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[44], VSI_NN_OP_SWISH, 1, 1, 197);
    node[44]->nn_param.swish.type = VSI_NN_SWISH;
    node[44]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Add_Add_62_182
      var       - node[45]
      name      - Add_Add_62
      operation - add
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[45], VSI_NN_OP_ADD, 2, 1, 182);

    /*-----------------------------------------
      lid       - Conv_Conv_63_195
      var       - node[46]
      name      - Conv_Conv_63
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[46], VSI_NN_OP_CONV2D, 3, 1, 195);
    node[46]->nn_param.conv2d.ksize[0] = 1;
    node[46]->nn_param.conv2d.ksize[1] = 1;
    node[46]->nn_param.conv2d.weights = 128;
    node[46]->nn_param.conv2d.stride[0] = 1;
    node[46]->nn_param.conv2d.stride[1] = 1;
    node[46]->nn_param.conv2d.pad[0] = 0;
    node[46]->nn_param.conv2d.pad[1] = 0;
    node[46]->nn_param.conv2d.pad[2] = 0;
    node[46]->nn_param.conv2d.pad[3] = 0;
    node[46]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[46]->nn_param.conv2d.group = 1;
    node[46]->nn_param.conv2d.dilation[0] = 1;
    node[46]->nn_param.conv2d.dilation[1] = 1;
    node[46]->nn_param.conv2d.multiplier = 0;
    node[46]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[46]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[46]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_64_193_Mul_Mul_65_187
      var       - node[47]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[47], VSI_NN_OP_SWISH, 1, 1, 187);
    node[47]->nn_param.swish.type = VSI_NN_SWISH;
    node[47]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_66_186
      var       - node[48]
      name      - Conv_Conv_66
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[48], VSI_NN_OP_CONV2D, 3, 1, 186);
    node[48]->nn_param.conv2d.ksize[0] = 3;
    node[48]->nn_param.conv2d.ksize[1] = 3;
    node[48]->nn_param.conv2d.weights = 128;
    node[48]->nn_param.conv2d.stride[0] = 1;
    node[48]->nn_param.conv2d.stride[1] = 1;
    node[48]->nn_param.conv2d.pad[0] = 1;
    node[48]->nn_param.conv2d.pad[1] = 1;
    node[48]->nn_param.conv2d.pad[2] = 1;
    node[48]->nn_param.conv2d.pad[3] = 1;
    node[48]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[48]->nn_param.conv2d.group = 1;
    node[48]->nn_param.conv2d.dilation[0] = 1;
    node[48]->nn_param.conv2d.dilation[1] = 1;
    node[48]->nn_param.conv2d.multiplier = 0;
    node[48]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[48]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[48]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_67_185_Mul_Mul_68_183
      var       - node[49]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[49], VSI_NN_OP_SWISH, 1, 1, 183);
    node[49]->nn_param.swish.type = VSI_NN_SWISH;
    node[49]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Add_Add_69_165
      var       - node[50]
      name      - Add_Add_69
      operation - add
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[50], VSI_NN_OP_ADD, 2, 1, 165);

    /*-----------------------------------------
      lid       - Conv_Conv_70_184
      var       - node[51]
      name      - Conv_Conv_70
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[51], VSI_NN_OP_CONV2D, 3, 1, 184);
    node[51]->nn_param.conv2d.ksize[0] = 1;
    node[51]->nn_param.conv2d.ksize[1] = 1;
    node[51]->nn_param.conv2d.weights = 128;
    node[51]->nn_param.conv2d.stride[0] = 1;
    node[51]->nn_param.conv2d.stride[1] = 1;
    node[51]->nn_param.conv2d.pad[0] = 0;
    node[51]->nn_param.conv2d.pad[1] = 0;
    node[51]->nn_param.conv2d.pad[2] = 0;
    node[51]->nn_param.conv2d.pad[3] = 0;
    node[51]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[51]->nn_param.conv2d.group = 1;
    node[51]->nn_param.conv2d.dilation[0] = 1;
    node[51]->nn_param.conv2d.dilation[1] = 1;
    node[51]->nn_param.conv2d.multiplier = 0;
    node[51]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[51]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[51]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_71_169_Mul_Mul_72_168
      var       - node[52]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[52], VSI_NN_OP_SWISH, 1, 1, 168);
    node[52]->nn_param.swish.type = VSI_NN_SWISH;
    node[52]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_73_166
      var       - node[53]
      name      - Conv_Conv_73
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[53], VSI_NN_OP_CONV2D, 3, 1, 166);
    node[53]->nn_param.conv2d.ksize[0] = 3;
    node[53]->nn_param.conv2d.ksize[1] = 3;
    node[53]->nn_param.conv2d.weights = 128;
    node[53]->nn_param.conv2d.stride[0] = 1;
    node[53]->nn_param.conv2d.stride[1] = 1;
    node[53]->nn_param.conv2d.pad[0] = 1;
    node[53]->nn_param.conv2d.pad[1] = 1;
    node[53]->nn_param.conv2d.pad[2] = 1;
    node[53]->nn_param.conv2d.pad[3] = 1;
    node[53]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[53]->nn_param.conv2d.group = 1;
    node[53]->nn_param.conv2d.dilation[0] = 1;
    node[53]->nn_param.conv2d.dilation[1] = 1;
    node[53]->nn_param.conv2d.multiplier = 0;
    node[53]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[53]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[53]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_74_167_Mul_Mul_75_153
      var       - node[54]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[54], VSI_NN_OP_SWISH, 1, 1, 153);
    node[54]->nn_param.swish.type = VSI_NN_SWISH;
    node[54]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Add_Add_76_152
      var       - node[55]
      name      - Add_Add_76
      operation - add
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[55], VSI_NN_OP_ADD, 2, 1, 152);

    /*-----------------------------------------
      lid       - Concat_Concat_80_138
      var       - node[56]
      name      - Concat_Concat_80
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[56], VSI_NN_OP_CONCAT, 2, 1, 138);
    node[56]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_81_123
      var       - node[57]
      name      - Conv_Conv_81
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[57], VSI_NN_OP_CONV2D, 3, 1, 123);
    node[57]->nn_param.conv2d.ksize[0] = 1;
    node[57]->nn_param.conv2d.ksize[1] = 1;
    node[57]->nn_param.conv2d.weights = 256;
    node[57]->nn_param.conv2d.stride[0] = 1;
    node[57]->nn_param.conv2d.stride[1] = 1;
    node[57]->nn_param.conv2d.pad[0] = 0;
    node[57]->nn_param.conv2d.pad[1] = 0;
    node[57]->nn_param.conv2d.pad[2] = 0;
    node[57]->nn_param.conv2d.pad[3] = 0;
    node[57]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[57]->nn_param.conv2d.group = 1;
    node[57]->nn_param.conv2d.dilation[0] = 1;
    node[57]->nn_param.conv2d.dilation[1] = 1;
    node[57]->nn_param.conv2d.multiplier = 0;
    node[57]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[57]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[57]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_82_124_Mul_Mul_83_111
      var       - node[58]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[58], VSI_NN_OP_SWISH, 1, 1, 111);
    node[58]->nn_param.swish.type = VSI_NN_SWISH;
    node[58]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_84_163
      var       - node[59]
      name      - Conv_Conv_84
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [3, 3, 256, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[59], VSI_NN_OP_CONV2D, 3, 1, 163);
    node[59]->nn_param.conv2d.ksize[0] = 3;
    node[59]->nn_param.conv2d.ksize[1] = 3;
    node[59]->nn_param.conv2d.weights = 512;
    node[59]->nn_param.conv2d.stride[0] = 2;
    node[59]->nn_param.conv2d.stride[1] = 2;
    node[59]->nn_param.conv2d.pad[0] = 1;
    node[59]->nn_param.conv2d.pad[1] = 1;
    node[59]->nn_param.conv2d.pad[2] = 1;
    node[59]->nn_param.conv2d.pad[3] = 1;
    node[59]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[59]->nn_param.conv2d.group = 1;
    node[59]->nn_param.conv2d.dilation[0] = 1;
    node[59]->nn_param.conv2d.dilation[1] = 1;
    node[59]->nn_param.conv2d.multiplier = 0;
    node[59]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[59]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[59]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_85_164_Mul_Mul_86_151
      var       - node[60]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[60], VSI_NN_OP_SWISH, 1, 1, 151);
    node[60]->nn_param.swish.type = VSI_NN_SWISH;
    node[60]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_97_148
      var       - node[61]
      name      - Conv_Conv_97
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[61], VSI_NN_OP_CONV2D, 3, 1, 148);
    node[61]->nn_param.conv2d.ksize[0] = 1;
    node[61]->nn_param.conv2d.ksize[1] = 1;
    node[61]->nn_param.conv2d.weights = 256;
    node[61]->nn_param.conv2d.stride[0] = 1;
    node[61]->nn_param.conv2d.stride[1] = 1;
    node[61]->nn_param.conv2d.pad[0] = 0;
    node[61]->nn_param.conv2d.pad[1] = 0;
    node[61]->nn_param.conv2d.pad[2] = 0;
    node[61]->nn_param.conv2d.pad[3] = 0;
    node[61]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[61]->nn_param.conv2d.group = 1;
    node[61]->nn_param.conv2d.dilation[0] = 1;
    node[61]->nn_param.conv2d.dilation[1] = 1;
    node[61]->nn_param.conv2d.multiplier = 0;
    node[61]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[61]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[61]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_87_176
      var       - node[62]
      name      - Conv_Conv_87
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[62], VSI_NN_OP_CONV2D, 3, 1, 176);
    node[62]->nn_param.conv2d.ksize[0] = 1;
    node[62]->nn_param.conv2d.ksize[1] = 1;
    node[62]->nn_param.conv2d.weights = 256;
    node[62]->nn_param.conv2d.stride[0] = 1;
    node[62]->nn_param.conv2d.stride[1] = 1;
    node[62]->nn_param.conv2d.pad[0] = 0;
    node[62]->nn_param.conv2d.pad[1] = 0;
    node[62]->nn_param.conv2d.pad[2] = 0;
    node[62]->nn_param.conv2d.pad[3] = 0;
    node[62]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[62]->nn_param.conv2d.group = 1;
    node[62]->nn_param.conv2d.dilation[0] = 1;
    node[62]->nn_param.conv2d.dilation[1] = 1;
    node[62]->nn_param.conv2d.multiplier = 0;
    node[62]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[62]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[62]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_98_149_Mul_Mul_99_134
      var       - node[63]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[63], VSI_NN_OP_SWISH, 1, 1, 134);
    node[63]->nn_param.swish.type = VSI_NN_SWISH;
    node[63]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_88_177_Mul_Mul_89_161
      var       - node[64]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[64], VSI_NN_OP_SWISH, 1, 1, 161);
    node[64]->nn_param.swish.type = VSI_NN_SWISH;
    node[64]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_90_194
      var       - node[65]
      name      - Conv_Conv_90
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[65], VSI_NN_OP_CONV2D, 3, 1, 194);
    node[65]->nn_param.conv2d.ksize[0] = 1;
    node[65]->nn_param.conv2d.ksize[1] = 1;
    node[65]->nn_param.conv2d.weights = 256;
    node[65]->nn_param.conv2d.stride[0] = 1;
    node[65]->nn_param.conv2d.stride[1] = 1;
    node[65]->nn_param.conv2d.pad[0] = 0;
    node[65]->nn_param.conv2d.pad[1] = 0;
    node[65]->nn_param.conv2d.pad[2] = 0;
    node[65]->nn_param.conv2d.pad[3] = 0;
    node[65]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[65]->nn_param.conv2d.group = 1;
    node[65]->nn_param.conv2d.dilation[0] = 1;
    node[65]->nn_param.conv2d.dilation[1] = 1;
    node[65]->nn_param.conv2d.multiplier = 0;
    node[65]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[65]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[65]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_91_181_Mul_Mul_92_180
      var       - node[66]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[66], VSI_NN_OP_SWISH, 1, 1, 180);
    node[66]->nn_param.swish.type = VSI_NN_SWISH;
    node[66]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_93_178
      var       - node[67]
      name      - Conv_Conv_93
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [3, 3, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[67], VSI_NN_OP_CONV2D, 3, 1, 178);
    node[67]->nn_param.conv2d.ksize[0] = 3;
    node[67]->nn_param.conv2d.ksize[1] = 3;
    node[67]->nn_param.conv2d.weights = 256;
    node[67]->nn_param.conv2d.stride[0] = 1;
    node[67]->nn_param.conv2d.stride[1] = 1;
    node[67]->nn_param.conv2d.pad[0] = 1;
    node[67]->nn_param.conv2d.pad[1] = 1;
    node[67]->nn_param.conv2d.pad[2] = 1;
    node[67]->nn_param.conv2d.pad[3] = 1;
    node[67]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[67]->nn_param.conv2d.group = 1;
    node[67]->nn_param.conv2d.dilation[0] = 1;
    node[67]->nn_param.conv2d.dilation[1] = 1;
    node[67]->nn_param.conv2d.multiplier = 0;
    node[67]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[67]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[67]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_94_179_Mul_Mul_95_162
      var       - node[68]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[68], VSI_NN_OP_SWISH, 1, 1, 162);
    node[68]->nn_param.swish.type = VSI_NN_SWISH;
    node[68]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Add_Add_96_147
      var       - node[69]
      name      - Add_Add_96
      operation - add
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[69], VSI_NN_OP_ADD, 2, 1, 147);

    /*-----------------------------------------
      lid       - Concat_Concat_100_133
      var       - node[70]
      name      - Concat_Concat_100
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[70], VSI_NN_OP_CONCAT, 2, 1, 133);
    node[70]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_101_118
      var       - node[71]
      name      - Conv_Conv_101
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[71], VSI_NN_OP_CONV2D, 3, 1, 118);
    node[71]->nn_param.conv2d.ksize[0] = 1;
    node[71]->nn_param.conv2d.ksize[1] = 1;
    node[71]->nn_param.conv2d.weights = 512;
    node[71]->nn_param.conv2d.stride[0] = 1;
    node[71]->nn_param.conv2d.stride[1] = 1;
    node[71]->nn_param.conv2d.pad[0] = 0;
    node[71]->nn_param.conv2d.pad[1] = 0;
    node[71]->nn_param.conv2d.pad[2] = 0;
    node[71]->nn_param.conv2d.pad[3] = 0;
    node[71]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[71]->nn_param.conv2d.group = 1;
    node[71]->nn_param.conv2d.dilation[0] = 1;
    node[71]->nn_param.conv2d.dilation[1] = 1;
    node[71]->nn_param.conv2d.multiplier = 0;
    node[71]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[71]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[71]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_102_119_Mul_Mul_103_107
      var       - node[72]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[72], VSI_NN_OP_SWISH, 1, 1, 107);
    node[72]->nn_param.swish.type = VSI_NN_SWISH;
    node[72]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_104_97
      var       - node[73]
      name      - Conv_Conv_104
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[73], VSI_NN_OP_CONV2D, 3, 1, 97);
    node[73]->nn_param.conv2d.ksize[0] = 1;
    node[73]->nn_param.conv2d.ksize[1] = 1;
    node[73]->nn_param.conv2d.weights = 256;
    node[73]->nn_param.conv2d.stride[0] = 1;
    node[73]->nn_param.conv2d.stride[1] = 1;
    node[73]->nn_param.conv2d.pad[0] = 0;
    node[73]->nn_param.conv2d.pad[1] = 0;
    node[73]->nn_param.conv2d.pad[2] = 0;
    node[73]->nn_param.conv2d.pad[3] = 0;
    node[73]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[73]->nn_param.conv2d.group = 1;
    node[73]->nn_param.conv2d.dilation[0] = 1;
    node[73]->nn_param.conv2d.dilation[1] = 1;
    node[73]->nn_param.conv2d.multiplier = 0;
    node[73]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[73]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[73]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_105_96_Mul_Mul_106_94
      var       - node[74]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[74], VSI_NN_OP_SWISH, 1, 1, 94);
    node[74]->nn_param.swish.type = VSI_NN_SWISH;
    node[74]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - MaxPool_MaxPool_107_95
      var       - node[75]
      name      - MaxPool_MaxPool_107
      operation - pooling
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[75], VSI_NN_OP_POOL, 1, 1, 95);
    node[75]->nn_param.pool.ksize[0] = 5;
    node[75]->nn_param.pool.ksize[1] = 5;
    node[75]->nn_param.pool.stride[0] = 1;
    node[75]->nn_param.pool.stride[1] = 1;
    node[75]->nn_param.pool.pad[0] = 2;
    node[75]->nn_param.pool.pad[1] = 2;
    node[75]->nn_param.pool.pad[2] = 2;
    node[75]->nn_param.pool.pad[3] = 2;
    node[75]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[75]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[75]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MaxPool_MaxPool_108_86
      var       - node[76]
      name      - MaxPool_MaxPool_108
      operation - pooling
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[76], VSI_NN_OP_POOL, 1, 1, 86);
    node[76]->nn_param.pool.ksize[0] = 5;
    node[76]->nn_param.pool.ksize[1] = 5;
    node[76]->nn_param.pool.stride[0] = 1;
    node[76]->nn_param.pool.stride[1] = 1;
    node[76]->nn_param.pool.pad[0] = 2;
    node[76]->nn_param.pool.pad[1] = 2;
    node[76]->nn_param.pool.pad[2] = 2;
    node[76]->nn_param.pool.pad[3] = 2;
    node[76]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[76]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[76]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - MaxPool_MaxPool_109_85
      var       - node[77]
      name      - MaxPool_MaxPool_109
      operation - pooling
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[77], VSI_NN_OP_POOL, 1, 1, 85);
    node[77]->nn_param.pool.ksize[0] = 5;
    node[77]->nn_param.pool.ksize[1] = 5;
    node[77]->nn_param.pool.stride[0] = 1;
    node[77]->nn_param.pool.stride[1] = 1;
    node[77]->nn_param.pool.pad[0] = 2;
    node[77]->nn_param.pool.pad[1] = 2;
    node[77]->nn_param.pool.pad[2] = 2;
    node[77]->nn_param.pool.pad[3] = 2;
    node[77]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[77]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[77]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Concat_Concat_110_82
      var       - node[78]
      name      - Concat_Concat_110
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
                  [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 1024, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[78], VSI_NN_OP_CONCAT, 4, 1, 82);
    node[78]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_111_81
      var       - node[79]
      name      - Conv_Conv_111
      operation - convolution
      input     - [20, 20, 1024, 1]
      filter    - [1, 1, 1024, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[79], VSI_NN_OP_CONV2D, 3, 1, 81);
    node[79]->nn_param.conv2d.ksize[0] = 1;
    node[79]->nn_param.conv2d.ksize[1] = 1;
    node[79]->nn_param.conv2d.weights = 512;
    node[79]->nn_param.conv2d.stride[0] = 1;
    node[79]->nn_param.conv2d.stride[1] = 1;
    node[79]->nn_param.conv2d.pad[0] = 0;
    node[79]->nn_param.conv2d.pad[1] = 0;
    node[79]->nn_param.conv2d.pad[2] = 0;
    node[79]->nn_param.conv2d.pad[3] = 0;
    node[79]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[79]->nn_param.conv2d.group = 1;
    node[79]->nn_param.conv2d.dilation[0] = 1;
    node[79]->nn_param.conv2d.dilation[1] = 1;
    node[79]->nn_param.conv2d.multiplier = 0;
    node[79]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[79]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[79]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_112_65_Mul_Mul_113_64
      var       - node[80]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[80], VSI_NN_OP_SWISH, 1, 1, 64);
    node[80]->nn_param.swish.type = VSI_NN_SWISH;
    node[80]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_114_48
      var       - node[81]
      name      - Conv_Conv_114
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[81], VSI_NN_OP_CONV2D, 3, 1, 48);
    node[81]->nn_param.conv2d.ksize[0] = 1;
    node[81]->nn_param.conv2d.ksize[1] = 1;
    node[81]->nn_param.conv2d.weights = 256;
    node[81]->nn_param.conv2d.stride[0] = 1;
    node[81]->nn_param.conv2d.stride[1] = 1;
    node[81]->nn_param.conv2d.pad[0] = 0;
    node[81]->nn_param.conv2d.pad[1] = 0;
    node[81]->nn_param.conv2d.pad[2] = 0;
    node[81]->nn_param.conv2d.pad[3] = 0;
    node[81]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[81]->nn_param.conv2d.group = 1;
    node[81]->nn_param.conv2d.dilation[0] = 1;
    node[81]->nn_param.conv2d.dilation[1] = 1;
    node[81]->nn_param.conv2d.multiplier = 0;
    node[81]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[81]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[81]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_115_49_Mul_Mul_116_36
      var       - node[82]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[82], VSI_NN_OP_SWISH, 1, 1, 36);
    node[82]->nn_param.swish.type = VSI_NN_SWISH;
    node[82]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Resize_Resize_118_122
      var       - node[83]
      name      - Resize_Resize_118
      operation - image_resize
      input     - [20, 20, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[83], VSI_NN_OP_RESIZE, 1, 1, 122);
    node[83]->nn_param.resize.type = VSI_NN_INTERPOLATION_NEAREST_NEIGHBOR;
    node[83]->nn_param.resize.factor = 0.0;
    node[83]->nn_param.resize.align_corners = FALSE;
    node[83]->nn_param.resize.half_pixel_centers = FALSE;
    node[83]->nn_param.resize.size[0] = 40;
    node[83]->nn_param.resize.size[1] = 40;

    /*-----------------------------------------
      lid       - Concat_Concat_119_110
      var       - node[84]
      name      - Concat_Concat_119
      operation - concat
      input     - [40, 40, 256, 1]
                  [40, 40, 256, 1]
      output    - [40, 40, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[84], VSI_NN_OP_CONCAT, 2, 1, 110);
    node[84]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_129_99
      var       - node[85]
      name      - Conv_Conv_129
      operation - convolution
      input     - [40, 40, 512, 1]
      filter    - [1, 1, 512, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[85], VSI_NN_OP_CONV2D, 3, 1, 99);
    node[85]->nn_param.conv2d.ksize[0] = 1;
    node[85]->nn_param.conv2d.ksize[1] = 1;
    node[85]->nn_param.conv2d.weights = 128;
    node[85]->nn_param.conv2d.stride[0] = 1;
    node[85]->nn_param.conv2d.stride[1] = 1;
    node[85]->nn_param.conv2d.pad[0] = 0;
    node[85]->nn_param.conv2d.pad[1] = 0;
    node[85]->nn_param.conv2d.pad[2] = 0;
    node[85]->nn_param.conv2d.pad[3] = 0;
    node[85]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[85]->nn_param.conv2d.group = 1;
    node[85]->nn_param.conv2d.dilation[0] = 1;
    node[85]->nn_param.conv2d.dilation[1] = 1;
    node[85]->nn_param.conv2d.multiplier = 0;
    node[85]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[85]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[85]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_120_150
      var       - node[86]
      name      - Conv_Conv_120
      operation - convolution
      input     - [40, 40, 512, 1]
      filter    - [1, 1, 512, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[86], VSI_NN_OP_CONV2D, 3, 1, 150);
    node[86]->nn_param.conv2d.ksize[0] = 1;
    node[86]->nn_param.conv2d.ksize[1] = 1;
    node[86]->nn_param.conv2d.weights = 128;
    node[86]->nn_param.conv2d.stride[0] = 1;
    node[86]->nn_param.conv2d.stride[1] = 1;
    node[86]->nn_param.conv2d.pad[0] = 0;
    node[86]->nn_param.conv2d.pad[1] = 0;
    node[86]->nn_param.conv2d.pad[2] = 0;
    node[86]->nn_param.conv2d.pad[3] = 0;
    node[86]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[86]->nn_param.conv2d.group = 1;
    node[86]->nn_param.conv2d.dilation[0] = 1;
    node[86]->nn_param.conv2d.dilation[1] = 1;
    node[86]->nn_param.conv2d.multiplier = 0;
    node[86]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[86]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[86]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_130_100_Mul_Mul_131_90
      var       - node[87]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[87], VSI_NN_OP_SWISH, 1, 1, 90);
    node[87]->nn_param.swish.type = VSI_NN_SWISH;
    node[87]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_121_137_Mul_Mul_122_136
      var       - node[88]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[88], VSI_NN_OP_SWISH, 1, 1, 136);
    node[88]->nn_param.swish.type = VSI_NN_SWISH;
    node[88]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_123_135
      var       - node[89]
      name      - Conv_Conv_123
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[89], VSI_NN_OP_CONV2D, 3, 1, 135);
    node[89]->nn_param.conv2d.ksize[0] = 1;
    node[89]->nn_param.conv2d.ksize[1] = 1;
    node[89]->nn_param.conv2d.weights = 128;
    node[89]->nn_param.conv2d.stride[0] = 1;
    node[89]->nn_param.conv2d.stride[1] = 1;
    node[89]->nn_param.conv2d.pad[0] = 0;
    node[89]->nn_param.conv2d.pad[1] = 0;
    node[89]->nn_param.conv2d.pad[2] = 0;
    node[89]->nn_param.conv2d.pad[3] = 0;
    node[89]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[89]->nn_param.conv2d.group = 1;
    node[89]->nn_param.conv2d.dilation[0] = 1;
    node[89]->nn_param.conv2d.dilation[1] = 1;
    node[89]->nn_param.conv2d.multiplier = 0;
    node[89]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[89]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[89]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_124_121_Mul_Mul_125_120
      var       - node[90]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[90], VSI_NN_OP_SWISH, 1, 1, 120);
    node[90]->nn_param.swish.type = VSI_NN_SWISH;
    node[90]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_126_108
      var       - node[91]
      name      - Conv_Conv_126
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[91], VSI_NN_OP_CONV2D, 3, 1, 108);
    node[91]->nn_param.conv2d.ksize[0] = 3;
    node[91]->nn_param.conv2d.ksize[1] = 3;
    node[91]->nn_param.conv2d.weights = 128;
    node[91]->nn_param.conv2d.stride[0] = 1;
    node[91]->nn_param.conv2d.stride[1] = 1;
    node[91]->nn_param.conv2d.pad[0] = 1;
    node[91]->nn_param.conv2d.pad[1] = 1;
    node[91]->nn_param.conv2d.pad[2] = 1;
    node[91]->nn_param.conv2d.pad[3] = 1;
    node[91]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[91]->nn_param.conv2d.group = 1;
    node[91]->nn_param.conv2d.dilation[0] = 1;
    node[91]->nn_param.conv2d.dilation[1] = 1;
    node[91]->nn_param.conv2d.multiplier = 0;
    node[91]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[91]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[91]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_127_109_Mul_Mul_128_98
      var       - node[92]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[92], VSI_NN_OP_SWISH, 1, 1, 98);
    node[92]->nn_param.swish.type = VSI_NN_SWISH;
    node[92]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Concat_Concat_132_88
      var       - node[93]
      name      - Concat_Concat_132
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[93], VSI_NN_OP_CONCAT, 2, 1, 88);
    node[93]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_133_87
      var       - node[94]
      name      - Conv_Conv_133
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[94], VSI_NN_OP_CONV2D, 3, 1, 87);
    node[94]->nn_param.conv2d.ksize[0] = 1;
    node[94]->nn_param.conv2d.ksize[1] = 1;
    node[94]->nn_param.conv2d.weights = 256;
    node[94]->nn_param.conv2d.stride[0] = 1;
    node[94]->nn_param.conv2d.stride[1] = 1;
    node[94]->nn_param.conv2d.pad[0] = 0;
    node[94]->nn_param.conv2d.pad[1] = 0;
    node[94]->nn_param.conv2d.pad[2] = 0;
    node[94]->nn_param.conv2d.pad[3] = 0;
    node[94]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[94]->nn_param.conv2d.group = 1;
    node[94]->nn_param.conv2d.dilation[0] = 1;
    node[94]->nn_param.conv2d.dilation[1] = 1;
    node[94]->nn_param.conv2d.multiplier = 0;
    node[94]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[94]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[94]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_134_71_Mul_Mul_135_70
      var       - node[95]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[95], VSI_NN_OP_SWISH, 1, 1, 70);
    node[95]->nn_param.swish.type = VSI_NN_SWISH;
    node[95]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_136_53
      var       - node[96]
      name      - Conv_Conv_136
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[96], VSI_NN_OP_CONV2D, 3, 1, 53);
    node[96]->nn_param.conv2d.ksize[0] = 1;
    node[96]->nn_param.conv2d.ksize[1] = 1;
    node[96]->nn_param.conv2d.weights = 128;
    node[96]->nn_param.conv2d.stride[0] = 1;
    node[96]->nn_param.conv2d.stride[1] = 1;
    node[96]->nn_param.conv2d.pad[0] = 0;
    node[96]->nn_param.conv2d.pad[1] = 0;
    node[96]->nn_param.conv2d.pad[2] = 0;
    node[96]->nn_param.conv2d.pad[3] = 0;
    node[96]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[96]->nn_param.conv2d.group = 1;
    node[96]->nn_param.conv2d.dilation[0] = 1;
    node[96]->nn_param.conv2d.dilation[1] = 1;
    node[96]->nn_param.conv2d.multiplier = 0;
    node[96]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[96]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[96]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_137_54_Mul_Mul_138_40
      var       - node[97]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[97], VSI_NN_OP_SWISH, 1, 1, 40);
    node[97]->nn_param.swish.type = VSI_NN_SWISH;
    node[97]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Resize_Resize_140_57
      var       - node[98]
      name      - Resize_Resize_140
      operation - image_resize
      input     - [40, 40, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[98], VSI_NN_OP_RESIZE, 1, 1, 57);
    node[98]->nn_param.resize.type = VSI_NN_INTERPOLATION_NEAREST_NEIGHBOR;
    node[98]->nn_param.resize.factor = 0.0;
    node[98]->nn_param.resize.align_corners = FALSE;
    node[98]->nn_param.resize.half_pixel_centers = FALSE;
    node[98]->nn_param.resize.size[0] = 80;
    node[98]->nn_param.resize.size[1] = 80;

    /*-----------------------------------------
      lid       - Concat_Concat_141_43
      var       - node[99]
      name      - Concat_Concat_141
      operation - concat
      input     - [80, 80, 128, 1]
                  [80, 80, 128, 1]
      output    - [80, 80, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[99], VSI_NN_OP_CONCAT, 2, 1, 43);
    node[99]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_151_31
      var       - node[100]
      name      - Conv_Conv_151
      operation - convolution
      input     - [80, 80, 256, 1]
      filter    - [1, 1, 256, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[100], VSI_NN_OP_CONV2D, 3, 1, 31);
    node[100]->nn_param.conv2d.ksize[0] = 1;
    node[100]->nn_param.conv2d.ksize[1] = 1;
    node[100]->nn_param.conv2d.weights = 64;
    node[100]->nn_param.conv2d.stride[0] = 1;
    node[100]->nn_param.conv2d.stride[1] = 1;
    node[100]->nn_param.conv2d.pad[0] = 0;
    node[100]->nn_param.conv2d.pad[1] = 0;
    node[100]->nn_param.conv2d.pad[2] = 0;
    node[100]->nn_param.conv2d.pad[3] = 0;
    node[100]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[100]->nn_param.conv2d.group = 1;
    node[100]->nn_param.conv2d.dilation[0] = 1;
    node[100]->nn_param.conv2d.dilation[1] = 1;
    node[100]->nn_param.conv2d.multiplier = 0;
    node[100]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[100]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[100]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_142_89
      var       - node[101]
      name      - Conv_Conv_142
      operation - convolution
      input     - [80, 80, 256, 1]
      filter    - [1, 1, 256, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[101], VSI_NN_OP_CONV2D, 3, 1, 89);
    node[101]->nn_param.conv2d.ksize[0] = 1;
    node[101]->nn_param.conv2d.ksize[1] = 1;
    node[101]->nn_param.conv2d.weights = 64;
    node[101]->nn_param.conv2d.stride[0] = 1;
    node[101]->nn_param.conv2d.stride[1] = 1;
    node[101]->nn_param.conv2d.pad[0] = 0;
    node[101]->nn_param.conv2d.pad[1] = 0;
    node[101]->nn_param.conv2d.pad[2] = 0;
    node[101]->nn_param.conv2d.pad[3] = 0;
    node[101]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[101]->nn_param.conv2d.group = 1;
    node[101]->nn_param.conv2d.dilation[0] = 1;
    node[101]->nn_param.conv2d.dilation[1] = 1;
    node[101]->nn_param.conv2d.multiplier = 0;
    node[101]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[101]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[101]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_152_32_Mul_Mul_153_23
      var       - node[102]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[102], VSI_NN_OP_SWISH, 1, 1, 23);
    node[102]->nn_param.swish.type = VSI_NN_SWISH;
    node[102]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_143_74_Mul_Mul_144_73
      var       - node[103]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[103], VSI_NN_OP_SWISH, 1, 1, 73);
    node[103]->nn_param.swish.type = VSI_NN_SWISH;
    node[103]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_145_72
      var       - node[104]
      name      - Conv_Conv_145
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[104], VSI_NN_OP_CONV2D, 3, 1, 72);
    node[104]->nn_param.conv2d.ksize[0] = 1;
    node[104]->nn_param.conv2d.ksize[1] = 1;
    node[104]->nn_param.conv2d.weights = 64;
    node[104]->nn_param.conv2d.stride[0] = 1;
    node[104]->nn_param.conv2d.stride[1] = 1;
    node[104]->nn_param.conv2d.pad[0] = 0;
    node[104]->nn_param.conv2d.pad[1] = 0;
    node[104]->nn_param.conv2d.pad[2] = 0;
    node[104]->nn_param.conv2d.pad[3] = 0;
    node[104]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[104]->nn_param.conv2d.group = 1;
    node[104]->nn_param.conv2d.dilation[0] = 1;
    node[104]->nn_param.conv2d.dilation[1] = 1;
    node[104]->nn_param.conv2d.multiplier = 0;
    node[104]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[104]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[104]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_146_56_Mul_Mul_147_55
      var       - node[105]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[105], VSI_NN_OP_SWISH, 1, 1, 55);
    node[105]->nn_param.swish.type = VSI_NN_SWISH;
    node[105]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_148_41
      var       - node[106]
      name      - Conv_Conv_148
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[106], VSI_NN_OP_CONV2D, 3, 1, 41);
    node[106]->nn_param.conv2d.ksize[0] = 3;
    node[106]->nn_param.conv2d.ksize[1] = 3;
    node[106]->nn_param.conv2d.weights = 64;
    node[106]->nn_param.conv2d.stride[0] = 1;
    node[106]->nn_param.conv2d.stride[1] = 1;
    node[106]->nn_param.conv2d.pad[0] = 1;
    node[106]->nn_param.conv2d.pad[1] = 1;
    node[106]->nn_param.conv2d.pad[2] = 1;
    node[106]->nn_param.conv2d.pad[3] = 1;
    node[106]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[106]->nn_param.conv2d.group = 1;
    node[106]->nn_param.conv2d.dilation[0] = 1;
    node[106]->nn_param.conv2d.dilation[1] = 1;
    node[106]->nn_param.conv2d.multiplier = 0;
    node[106]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[106]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[106]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_149_42_Mul_Mul_150_30
      var       - node[107]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[107], VSI_NN_OP_SWISH, 1, 1, 30);
    node[107]->nn_param.swish.type = VSI_NN_SWISH;
    node[107]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Concat_Concat_154_22
      var       - node[108]
      name      - Concat_Concat_154
      operation - concat
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[108], VSI_NN_OP_CONCAT, 2, 1, 22);
    node[108]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_155_16
      var       - node[109]
      name      - Conv_Conv_155
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[109], VSI_NN_OP_CONV2D, 3, 1, 16);
    node[109]->nn_param.conv2d.ksize[0] = 1;
    node[109]->nn_param.conv2d.ksize[1] = 1;
    node[109]->nn_param.conv2d.weights = 128;
    node[109]->nn_param.conv2d.stride[0] = 1;
    node[109]->nn_param.conv2d.stride[1] = 1;
    node[109]->nn_param.conv2d.pad[0] = 0;
    node[109]->nn_param.conv2d.pad[1] = 0;
    node[109]->nn_param.conv2d.pad[2] = 0;
    node[109]->nn_param.conv2d.pad[3] = 0;
    node[109]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[109]->nn_param.conv2d.group = 1;
    node[109]->nn_param.conv2d.dilation[0] = 1;
    node[109]->nn_param.conv2d.dilation[1] = 1;
    node[109]->nn_param.conv2d.multiplier = 0;
    node[109]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[109]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[109]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_156_17_Mul_Mul_157_11
      var       - node[110]
      name      - swish
      operation - swish
      input     - [80, 80, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[110], VSI_NN_OP_SWISH, 1, 1, 11);
    node[110]->nn_param.swish.type = VSI_NN_SWISH;
    node[110]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_198_8
      var       - node[111]
      name      - Conv_Conv_198
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 255]
      output    - [80, 80, 255, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[111], VSI_NN_OP_CONV2D, 3, 1, 8);
    node[111]->nn_param.conv2d.ksize[0] = 1;
    node[111]->nn_param.conv2d.ksize[1] = 1;
    node[111]->nn_param.conv2d.weights = 255;
    node[111]->nn_param.conv2d.stride[0] = 1;
    node[111]->nn_param.conv2d.stride[1] = 1;
    node[111]->nn_param.conv2d.pad[0] = 0;
    node[111]->nn_param.conv2d.pad[1] = 0;
    node[111]->nn_param.conv2d.pad[2] = 0;
    node[111]->nn_param.conv2d.pad[3] = 0;
    node[111]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[111]->nn_param.conv2d.group = 1;
    node[111]->nn_param.conv2d.dilation[0] = 1;
    node[111]->nn_param.conv2d.dilation[1] = 1;
    node[111]->nn_param.conv2d.multiplier = 0;
    node[111]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[111]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[111]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_158_68
      var       - node[112]
      name      - Conv_Conv_158
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[112], VSI_NN_OP_CONV2D, 3, 1, 68);
    node[112]->nn_param.conv2d.ksize[0] = 3;
    node[112]->nn_param.conv2d.ksize[1] = 3;
    node[112]->nn_param.conv2d.weights = 128;
    node[112]->nn_param.conv2d.stride[0] = 2;
    node[112]->nn_param.conv2d.stride[1] = 2;
    node[112]->nn_param.conv2d.pad[0] = 1;
    node[112]->nn_param.conv2d.pad[1] = 1;
    node[112]->nn_param.conv2d.pad[2] = 1;
    node[112]->nn_param.conv2d.pad[3] = 1;
    node[112]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[112]->nn_param.conv2d.group = 1;
    node[112]->nn_param.conv2d.dilation[0] = 1;
    node[112]->nn_param.conv2d.dilation[1] = 1;
    node[112]->nn_param.conv2d.multiplier = 0;
    node[112]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[112]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[112]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_159_69_Mul_Mul_160_52
      var       - node[113]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[113], VSI_NN_OP_SWISH, 1, 1, 52);
    node[113]->nn_param.swish.type = VSI_NN_SWISH;
    node[113]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Concat_Concat_161_39
      var       - node[114]
      name      - Concat_Concat_161
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[114], VSI_NN_OP_CONCAT, 2, 1, 39);
    node[114]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_171_28
      var       - node[115]
      name      - Conv_Conv_171
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[115], VSI_NN_OP_CONV2D, 3, 1, 28);
    node[115]->nn_param.conv2d.ksize[0] = 1;
    node[115]->nn_param.conv2d.ksize[1] = 1;
    node[115]->nn_param.conv2d.weights = 128;
    node[115]->nn_param.conv2d.stride[0] = 1;
    node[115]->nn_param.conv2d.stride[1] = 1;
    node[115]->nn_param.conv2d.pad[0] = 0;
    node[115]->nn_param.conv2d.pad[1] = 0;
    node[115]->nn_param.conv2d.pad[2] = 0;
    node[115]->nn_param.conv2d.pad[3] = 0;
    node[115]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[115]->nn_param.conv2d.group = 1;
    node[115]->nn_param.conv2d.dilation[0] = 1;
    node[115]->nn_param.conv2d.dilation[1] = 1;
    node[115]->nn_param.conv2d.multiplier = 0;
    node[115]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[115]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[115]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_162_83
      var       - node[116]
      name      - Conv_Conv_162
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[116], VSI_NN_OP_CONV2D, 3, 1, 83);
    node[116]->nn_param.conv2d.ksize[0] = 1;
    node[116]->nn_param.conv2d.ksize[1] = 1;
    node[116]->nn_param.conv2d.weights = 128;
    node[116]->nn_param.conv2d.stride[0] = 1;
    node[116]->nn_param.conv2d.stride[1] = 1;
    node[116]->nn_param.conv2d.pad[0] = 0;
    node[116]->nn_param.conv2d.pad[1] = 0;
    node[116]->nn_param.conv2d.pad[2] = 0;
    node[116]->nn_param.conv2d.pad[3] = 0;
    node[116]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[116]->nn_param.conv2d.group = 1;
    node[116]->nn_param.conv2d.dilation[0] = 1;
    node[116]->nn_param.conv2d.dilation[1] = 1;
    node[116]->nn_param.conv2d.multiplier = 0;
    node[116]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[116]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[116]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_172_29_Mul_Mul_173_21
      var       - node[117]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[117], VSI_NN_OP_SWISH, 1, 1, 21);
    node[117]->nn_param.swish.type = VSI_NN_SWISH;
    node[117]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_163_84_Mul_Mul_164_67
      var       - node[118]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[118], VSI_NN_OP_SWISH, 1, 1, 67);
    node[118]->nn_param.swish.type = VSI_NN_SWISH;
    node[118]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_165_66
      var       - node[119]
      name      - Conv_Conv_165
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[119], VSI_NN_OP_CONV2D, 3, 1, 66);
    node[119]->nn_param.conv2d.ksize[0] = 1;
    node[119]->nn_param.conv2d.ksize[1] = 1;
    node[119]->nn_param.conv2d.weights = 128;
    node[119]->nn_param.conv2d.stride[0] = 1;
    node[119]->nn_param.conv2d.stride[1] = 1;
    node[119]->nn_param.conv2d.pad[0] = 0;
    node[119]->nn_param.conv2d.pad[1] = 0;
    node[119]->nn_param.conv2d.pad[2] = 0;
    node[119]->nn_param.conv2d.pad[3] = 0;
    node[119]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[119]->nn_param.conv2d.group = 1;
    node[119]->nn_param.conv2d.dilation[0] = 1;
    node[119]->nn_param.conv2d.dilation[1] = 1;
    node[119]->nn_param.conv2d.multiplier = 0;
    node[119]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[119]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[119]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_166_51_Mul_Mul_167_50
      var       - node[120]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[120], VSI_NN_OP_SWISH, 1, 1, 50);
    node[120]->nn_param.swish.type = VSI_NN_SWISH;
    node[120]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_168_37
      var       - node[121]
      name      - Conv_Conv_168
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[121], VSI_NN_OP_CONV2D, 3, 1, 37);
    node[121]->nn_param.conv2d.ksize[0] = 3;
    node[121]->nn_param.conv2d.ksize[1] = 3;
    node[121]->nn_param.conv2d.weights = 128;
    node[121]->nn_param.conv2d.stride[0] = 1;
    node[121]->nn_param.conv2d.stride[1] = 1;
    node[121]->nn_param.conv2d.pad[0] = 1;
    node[121]->nn_param.conv2d.pad[1] = 1;
    node[121]->nn_param.conv2d.pad[2] = 1;
    node[121]->nn_param.conv2d.pad[3] = 1;
    node[121]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[121]->nn_param.conv2d.group = 1;
    node[121]->nn_param.conv2d.dilation[0] = 1;
    node[121]->nn_param.conv2d.dilation[1] = 1;
    node[121]->nn_param.conv2d.multiplier = 0;
    node[121]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[121]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[121]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_169_38_Mul_Mul_170_27
      var       - node[122]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[122], VSI_NN_OP_SWISH, 1, 1, 27);
    node[122]->nn_param.swish.type = VSI_NN_SWISH;
    node[122]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Concat_Concat_174_20
      var       - node[123]
      name      - Concat_Concat_174
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[123], VSI_NN_OP_CONCAT, 2, 1, 20);
    node[123]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_175_14
      var       - node[124]
      name      - Conv_Conv_175
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[124], VSI_NN_OP_CONV2D, 3, 1, 14);
    node[124]->nn_param.conv2d.ksize[0] = 1;
    node[124]->nn_param.conv2d.ksize[1] = 1;
    node[124]->nn_param.conv2d.weights = 256;
    node[124]->nn_param.conv2d.stride[0] = 1;
    node[124]->nn_param.conv2d.stride[1] = 1;
    node[124]->nn_param.conv2d.pad[0] = 0;
    node[124]->nn_param.conv2d.pad[1] = 0;
    node[124]->nn_param.conv2d.pad[2] = 0;
    node[124]->nn_param.conv2d.pad[3] = 0;
    node[124]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[124]->nn_param.conv2d.group = 1;
    node[124]->nn_param.conv2d.dilation[0] = 1;
    node[124]->nn_param.conv2d.dilation[1] = 1;
    node[124]->nn_param.conv2d.multiplier = 0;
    node[124]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[124]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[124]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_176_15_Mul_Mul_177_10
      var       - node[125]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[125], VSI_NN_OP_SWISH, 1, 1, 10);
    node[125]->nn_param.swish.type = VSI_NN_SWISH;
    node[125]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_200_7
      var       - node[126]
      name      - Conv_Conv_200
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 255]
      output    - [40, 40, 255, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[126], VSI_NN_OP_CONV2D, 3, 1, 7);
    node[126]->nn_param.conv2d.ksize[0] = 1;
    node[126]->nn_param.conv2d.ksize[1] = 1;
    node[126]->nn_param.conv2d.weights = 255;
    node[126]->nn_param.conv2d.stride[0] = 1;
    node[126]->nn_param.conv2d.stride[1] = 1;
    node[126]->nn_param.conv2d.pad[0] = 0;
    node[126]->nn_param.conv2d.pad[1] = 0;
    node[126]->nn_param.conv2d.pad[2] = 0;
    node[126]->nn_param.conv2d.pad[3] = 0;
    node[126]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[126]->nn_param.conv2d.group = 1;
    node[126]->nn_param.conv2d.dilation[0] = 1;
    node[126]->nn_param.conv2d.dilation[1] = 1;
    node[126]->nn_param.conv2d.multiplier = 0;
    node[126]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[126]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[126]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_178_62
      var       - node[127]
      name      - Conv_Conv_178
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [3, 3, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[127], VSI_NN_OP_CONV2D, 3, 1, 62);
    node[127]->nn_param.conv2d.ksize[0] = 3;
    node[127]->nn_param.conv2d.ksize[1] = 3;
    node[127]->nn_param.conv2d.weights = 256;
    node[127]->nn_param.conv2d.stride[0] = 2;
    node[127]->nn_param.conv2d.stride[1] = 2;
    node[127]->nn_param.conv2d.pad[0] = 1;
    node[127]->nn_param.conv2d.pad[1] = 1;
    node[127]->nn_param.conv2d.pad[2] = 1;
    node[127]->nn_param.conv2d.pad[3] = 1;
    node[127]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[127]->nn_param.conv2d.group = 1;
    node[127]->nn_param.conv2d.dilation[0] = 1;
    node[127]->nn_param.conv2d.dilation[1] = 1;
    node[127]->nn_param.conv2d.multiplier = 0;
    node[127]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[127]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[127]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_179_63_Mul_Mul_180_47
      var       - node[128]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[128], VSI_NN_OP_SWISH, 1, 1, 47);
    node[128]->nn_param.swish.type = VSI_NN_SWISH;
    node[128]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Concat_Concat_181_35
      var       - node[129]
      name      - Concat_Concat_181
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[129], VSI_NN_OP_CONCAT, 2, 1, 35);
    node[129]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_191_25
      var       - node[130]
      name      - Conv_Conv_191
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[130], VSI_NN_OP_CONV2D, 3, 1, 25);
    node[130]->nn_param.conv2d.ksize[0] = 1;
    node[130]->nn_param.conv2d.ksize[1] = 1;
    node[130]->nn_param.conv2d.weights = 256;
    node[130]->nn_param.conv2d.stride[0] = 1;
    node[130]->nn_param.conv2d.stride[1] = 1;
    node[130]->nn_param.conv2d.pad[0] = 0;
    node[130]->nn_param.conv2d.pad[1] = 0;
    node[130]->nn_param.conv2d.pad[2] = 0;
    node[130]->nn_param.conv2d.pad[3] = 0;
    node[130]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[130]->nn_param.conv2d.group = 1;
    node[130]->nn_param.conv2d.dilation[0] = 1;
    node[130]->nn_param.conv2d.dilation[1] = 1;
    node[130]->nn_param.conv2d.multiplier = 0;
    node[130]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[130]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[130]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Conv_Conv_182_77
      var       - node[131]
      name      - Conv_Conv_182
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[131], VSI_NN_OP_CONV2D, 3, 1, 77);
    node[131]->nn_param.conv2d.ksize[0] = 1;
    node[131]->nn_param.conv2d.ksize[1] = 1;
    node[131]->nn_param.conv2d.weights = 256;
    node[131]->nn_param.conv2d.stride[0] = 1;
    node[131]->nn_param.conv2d.stride[1] = 1;
    node[131]->nn_param.conv2d.pad[0] = 0;
    node[131]->nn_param.conv2d.pad[1] = 0;
    node[131]->nn_param.conv2d.pad[2] = 0;
    node[131]->nn_param.conv2d.pad[3] = 0;
    node[131]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[131]->nn_param.conv2d.group = 1;
    node[131]->nn_param.conv2d.dilation[0] = 1;
    node[131]->nn_param.conv2d.dilation[1] = 1;
    node[131]->nn_param.conv2d.multiplier = 0;
    node[131]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[131]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[131]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_192_26_Mul_Mul_193_19
      var       - node[132]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[132], VSI_NN_OP_SWISH, 1, 1, 19);
    node[132]->nn_param.swish.type = VSI_NN_SWISH;
    node[132]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_183_78_Mul_Mul_184_61
      var       - node[133]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[133], VSI_NN_OP_SWISH, 1, 1, 61);
    node[133]->nn_param.swish.type = VSI_NN_SWISH;
    node[133]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_185_60
      var       - node[134]
      name      - Conv_Conv_185
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[134], VSI_NN_OP_CONV2D, 3, 1, 60);
    node[134]->nn_param.conv2d.ksize[0] = 1;
    node[134]->nn_param.conv2d.ksize[1] = 1;
    node[134]->nn_param.conv2d.weights = 256;
    node[134]->nn_param.conv2d.stride[0] = 1;
    node[134]->nn_param.conv2d.stride[1] = 1;
    node[134]->nn_param.conv2d.pad[0] = 0;
    node[134]->nn_param.conv2d.pad[1] = 0;
    node[134]->nn_param.conv2d.pad[2] = 0;
    node[134]->nn_param.conv2d.pad[3] = 0;
    node[134]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[134]->nn_param.conv2d.group = 1;
    node[134]->nn_param.conv2d.dilation[0] = 1;
    node[134]->nn_param.conv2d.dilation[1] = 1;
    node[134]->nn_param.conv2d.multiplier = 0;
    node[134]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[134]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[134]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_186_46_Mul_Mul_187_45
      var       - node[135]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[135], VSI_NN_OP_SWISH, 1, 1, 45);
    node[135]->nn_param.swish.type = VSI_NN_SWISH;
    node[135]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_188_33
      var       - node[136]
      name      - Conv_Conv_188
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [3, 3, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[136], VSI_NN_OP_CONV2D, 3, 1, 33);
    node[136]->nn_param.conv2d.ksize[0] = 3;
    node[136]->nn_param.conv2d.ksize[1] = 3;
    node[136]->nn_param.conv2d.weights = 256;
    node[136]->nn_param.conv2d.stride[0] = 1;
    node[136]->nn_param.conv2d.stride[1] = 1;
    node[136]->nn_param.conv2d.pad[0] = 1;
    node[136]->nn_param.conv2d.pad[1] = 1;
    node[136]->nn_param.conv2d.pad[2] = 1;
    node[136]->nn_param.conv2d.pad[3] = 1;
    node[136]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[136]->nn_param.conv2d.group = 1;
    node[136]->nn_param.conv2d.dilation[0] = 1;
    node[136]->nn_param.conv2d.dilation[1] = 1;
    node[136]->nn_param.conv2d.multiplier = 0;
    node[136]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[136]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[136]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_189_34_Mul_Mul_190_24
      var       - node[137]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[137], VSI_NN_OP_SWISH, 1, 1, 24);
    node[137]->nn_param.swish.type = VSI_NN_SWISH;
    node[137]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Concat_Concat_194_18
      var       - node[138]
      name      - Concat_Concat_194
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[138], VSI_NN_OP_CONCAT, 2, 1, 18);
    node[138]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - Conv_Conv_195_12
      var       - node[139]
      name      - Conv_Conv_195
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[139], VSI_NN_OP_CONV2D, 3, 1, 12);
    node[139]->nn_param.conv2d.ksize[0] = 1;
    node[139]->nn_param.conv2d.ksize[1] = 1;
    node[139]->nn_param.conv2d.weights = 512;
    node[139]->nn_param.conv2d.stride[0] = 1;
    node[139]->nn_param.conv2d.stride[1] = 1;
    node[139]->nn_param.conv2d.pad[0] = 0;
    node[139]->nn_param.conv2d.pad[1] = 0;
    node[139]->nn_param.conv2d.pad[2] = 0;
    node[139]->nn_param.conv2d.pad[3] = 0;
    node[139]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[139]->nn_param.conv2d.group = 1;
    node[139]->nn_param.conv2d.dilation[0] = 1;
    node[139]->nn_param.conv2d.dilation[1] = 1;
    node[139]->nn_param.conv2d.multiplier = 0;
    node[139]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[139]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[139]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - Sigmoid_Sigmoid_196_13_Mul_Mul_197_9
      var       - node[140]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[140], VSI_NN_OP_SWISH, 1, 1, 9);
    node[140]->nn_param.swish.type = VSI_NN_SWISH;
    node[140]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - Conv_Conv_202_6
      var       - node[141]
      name      - Conv_Conv_202
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 255]
      output    - [20, 20, 255, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[141], VSI_NN_OP_CONV2D, 3, 1, 6);
    node[141]->nn_param.conv2d.ksize[0] = 1;
    node[141]->nn_param.conv2d.ksize[1] = 1;
    node[141]->nn_param.conv2d.weights = 255;
    node[141]->nn_param.conv2d.stride[0] = 1;
    node[141]->nn_param.conv2d.stride[1] = 1;
    node[141]->nn_param.conv2d.pad[0] = 0;
    node[141]->nn_param.conv2d.pad[1] = 0;
    node[141]->nn_param.conv2d.pad[2] = 0;
    node[141]->nn_param.conv2d.pad[3] = 0;
    node[141]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[141]->nn_param.conv2d.group = 1;
    node[141]->nn_param.conv2d.dilation[0] = 1;
    node[141]->nn_param.conv2d.dilation[1] = 1;
    node[141]->nn_param.conv2d.multiplier = 0;
    node[141]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[141]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[141]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    }
    else
    {
    NEW_VXNODE(node[0], VSI_NN_OP_NBG, 1, 3, 0);
    node[0]->nn_param.nbg.type = VSI_NN_NBG_FILE;
    node[0]->nn_param.nbg.url = data_file_name;

    }

/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @attach_Reshape_Reshape_199/out0_0:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 80;
    attr.size[1] = 80;
    attr.size[2] = 255;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.08489479124546051;
    attr.dtype.zero_point = 208;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_UINT8);

    /* @attach_Reshape_Reshape_201/out0_1:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 40;
    attr.size[1] = 40;
    attr.size[2] = 255;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.07565876096487045;
    attr.dtype.zero_point = 200;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_UINT8);

    /* @attach_Reshape_Reshape_203/out0_2:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 20;
    attr.size[1] = 20;
    attr.size[2] = 255;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.07304223626852036;
    attr.dtype.zero_point = 190;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[2], attr, VSI_NN_TYPE_UINT8);

    /* @images_205:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 640;
    attr.size[1] = 640;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003921568859368563;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[3], attr, VSI_NN_TYPE_UINT8);



    if( !inference_with_nbg )
    {
    /* @Conv_Conv_0_190:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 6;
    attr.size[1] = 6;
    attr.size[2] = 3;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.2132832556962967;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_UINT8, 128, 3456);

    /* @Conv_Conv_0_190:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0008364049717783928;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_INT32, 0, 128);

    /* @Conv_Conv_3_174:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.008123219944536686;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_UINT8, 4182644, 18432);

    /* @Conv_Conv_3_174:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0011253944830968976;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_INT32, 4182388, 256);

    /* @Conv_Conv_16_145:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007109948433935642;
    attr.dtype.zero_point = 157;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_UINT8, 1902336, 2048);

    /* @Conv_Conv_16_145:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0013372177490964532;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_INT32, 1902208, 128);

    /* @Conv_Conv_6_170:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005300343502312899;
    attr.dtype.zero_point = 191;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_UINT8, 4885492, 2048);

    /* @Conv_Conv_6_170:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0009968726662918925;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_INT32, 4885364, 128);

    /* @Conv_Conv_9_192:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.057911574840545654;
    attr.dtype.zero_point = 112;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_UINT8, 7255668, 1024);

    /* @Conv_Conv_9_192:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0008603384485468268;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_INT32, 7255540, 128);

    /* @Conv_Conv_12_172:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006764058489352465;
    attr.dtype.zero_point = 113;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_UINT8, 1355392, 9216);

    /* @Conv_Conv_12_172:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00035344550269655883;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_INT32, 1355264, 128);

    /* @Conv_Conv_20_116:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006935855373740196;
    attr.dtype.zero_point = 151;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_UINT8, 4012660, 4096);

    /* @Conv_Conv_20_116:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00036144774639979005;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_INT32, 4012404, 256);

    /* @Conv_Conv_23_104:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0021823032293468714;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_UINT8, 4017268, 73728);

    /* @Conv_Conv_23_104:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 7.376319990726188e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_INT32, 4016756, 512);

    /* @Conv_Conv_43_80:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.012595176696777344;
    attr.dtype.zero_point = 156;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_UINT8, 4201332, 8192);

    /* @Conv_Conv_43_80:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00024041884171310812;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_INT32, 4201076, 256);

    /* @Conv_Conv_26_125:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0036936281248927116;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_UINT8, 4091252, 8192);

    /* @Conv_Conv_26_125:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 7.050458953017369e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_INT32, 4090996, 256);

    /* @Conv_Conv_29_142:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.022251756861805916;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_UINT8, 4099700, 4096);

    /* @Conv_Conv_29_142:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016069592675194144;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_INT32, 4099444, 256);

    /* @Conv_Conv_32_127:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0033081118017435074;
    attr.dtype.zero_point = 157;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_UINT8, 4104052, 36864);

    /* @Conv_Conv_32_127:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 7.792893302394077e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_INT32, 4103796, 256);

    /* @Conv_Conv_36_129:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.016224373131990433;
    attr.dtype.zero_point = 95;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_UINT8, 4141172, 4096);

    /* @Conv_Conv_36_129:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002348165144212544;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_INT32, 4140916, 256);

    /* @Conv_Conv_39_102:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007488714065402746;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_UINT8, 4145524, 36864);

    /* @Conv_Conv_39_102:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016296976536978036;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_INT32, 4145268, 256);

    /* @Conv_Conv_47_58:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006058035418391228;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_UINT8, 4210036, 16384);

    /* @Conv_Conv_47_58:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00018815767543856055;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_INT32, 4209524, 512);

    /* @Conv_Conv_50_156:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005526114255189896;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_UINT8, 4227444, 294912);

    /* @Conv_Conv_50_156:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00012765475548803806;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_INT32, 4226420, 1024);

    /* @Conv_Conv_77_141:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009754646569490433;
    attr.dtype.zero_point = 146;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_UINT8, 5052916, 32768);

    /* @Conv_Conv_77_141:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002174646797357127;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_INT32, 5052404, 512);

    /* @Conv_Conv_53_201:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007966560311615467;
    attr.dtype.zero_point = 184;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_UINT8, 4522868, 32768);

    /* @Conv_Conv_53_201:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001776020653778687;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_INT32, 4522356, 512);

    /* @Conv_Conv_56_204:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.021737486124038696;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_UINT8, 4556148, 16384);

    /* @Conv_Conv_56_204:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00029015104519203305;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_INT32, 4555636, 512);

    /* @Conv_Conv_59_199:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003179156919941306;
    attr.dtype.zero_point = 157;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_UINT8, 4573044, 147456);

    /* @Conv_Conv_59_199:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.000110309396404773;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_INT32, 4572532, 512);

    /* @Conv_Conv_63_195:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.016731588169932365;
    attr.dtype.zero_point = 118;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_UINT8, 4721012, 16384);

    /* @Conv_Conv_63_195:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002102275175275281;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_INT32, 4720500, 512);

    /* @Conv_Conv_66_186:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.004429674241691828;
    attr.dtype.zero_point = 148;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_UINT8, 4737908, 147456);

    /* @Conv_Conv_66_186:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001635311491554603;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_INT32, 4737396, 512);

    /* @Conv_Conv_70_184:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.008422610349953175;
    attr.dtype.zero_point = 129;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_UINT8, 4888052, 16384);

    /* @Conv_Conv_70_184:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002384838298894465;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_INT32, 4887540, 512);

    /* @Conv_Conv_73_166:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0071656047366559505;
    attr.dtype.zero_point = 117;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_UINT8, 4904948, 147456);

    /* @Conv_Conv_73_166:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00023402371152769774;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_INT32, 4904436, 512);

    /* @Conv_Conv_81_123:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003918573725968599;
    attr.dtype.zero_point = 109;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_UINT8, 5086708, 65536);

    /* @Conv_Conv_81_123:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001663438742980361;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_INT32, 5085684, 1024);

    /* @Conv_Conv_84_163:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0035942504182457924;
    attr.dtype.zero_point = 109;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_UINT8, 5154292, 1179648);

    /* @Conv_Conv_84_163:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00010285487223882228;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_INT32, 5152244, 2048);

    /* @Conv_Conv_97_148:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00909903459250927;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_UINT8, 7124468, 131072);

    /* @Conv_Conv_97_148:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002627743815537542;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_INT32, 7123444, 1024);

    /* @Conv_Conv_87_176:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00430411659181118;
    attr.dtype.zero_point = 145;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_UINT8, 6334964, 131072);

    /* @Conv_Conv_87_176:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001243001752300188;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_INT32, 6333940, 1024);

    /* @Conv_Conv_90_194:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0191442109644413;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[56], attr, VSI_NN_TYPE_UINT8, 6467060, 65536);

    /* @Conv_Conv_90_194:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0003844256279990077;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[57], attr, VSI_NN_TYPE_INT32, 6466036, 1024);

    /* @Conv_Conv_93_178:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0036736063193529844;
    attr.dtype.zero_point = 147;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[58], attr, VSI_NN_TYPE_UINT8, 6533620, 589824);

    /* @Conv_Conv_93_178:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001251715875696391;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[59], attr, VSI_NN_TYPE_INT32, 6532596, 1024);

    /* @Conv_Conv_101_118:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005403044633567333;
    attr.dtype.zero_point = 107;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[60], attr, VSI_NN_TYPE_UINT8, 5632, 262144);

    /* @Conv_Conv_101_118:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001991664175875485;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[61], attr, VSI_NN_TYPE_INT32, 3584, 2048);

    /* @Conv_Conv_104_97:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.004150948487222195;
    attr.dtype.zero_point = 159;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[62], attr, VSI_NN_TYPE_UINT8, 268800, 131072);

    /* @Conv_Conv_104_97:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00012605382653418928;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[63], attr, VSI_NN_TYPE_INT32, 267776, 1024);

    /* @Conv_Conv_111_81:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00451302994042635;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[64], attr, VSI_NN_TYPE_UINT8, 401920, 524288);

    /* @Conv_Conv_111_81:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001039683775161393;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[65], attr, VSI_NN_TYPE_INT32, 399872, 2048);

    /* @Conv_Conv_114_48:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.010493258945643902;
    attr.dtype.zero_point = 165;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[66], attr, VSI_NN_TYPE_UINT8, 927232, 131072);

    /* @Conv_Conv_114_48:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00021552236285060644;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[67], attr, VSI_NN_TYPE_INT32, 926208, 1024);

    /* @Conv_Conv_129_99:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006157001946121454;
    attr.dtype.zero_point = 158;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[68], attr, VSI_NN_TYPE_UINT8, 1289728, 65536);

    /* @Conv_Conv_129_99:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001761918538250029;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[69], attr, VSI_NN_TYPE_INT32, 1289216, 512);

    /* @Conv_Conv_120_150:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007059021387249231;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[70], attr, VSI_NN_TYPE_UINT8, 1058816, 65536);

    /* @Conv_Conv_120_150:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002020044921664521;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[71], attr, VSI_NN_TYPE_INT32, 1058304, 512);

    /* @Conv_Conv_123_135:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.012190792709589005;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[72], attr, VSI_NN_TYPE_UINT8, 1124864, 16384);

    /* @Conv_Conv_123_135:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00023326459631789476;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[73], attr, VSI_NN_TYPE_INT32, 1124352, 512);

    /* @Conv_Conv_126_108:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.004703606013208628;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[74], attr, VSI_NN_TYPE_UINT8, 1141760, 147456);

    /* @Conv_Conv_126_108:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 9.511082316748798e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[75], attr, VSI_NN_TYPE_INT32, 1141248, 512);

    /* @Conv_Conv_133_87:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.010936480015516281;
    attr.dtype.zero_point = 153;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[76], attr, VSI_NN_TYPE_UINT8, 1365632, 65536);

    /* @Conv_Conv_133_87:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00024253658193629235;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[77], attr, VSI_NN_TYPE_INT32, 1364608, 1024);

    /* @Conv_Conv_136_53:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005018447060137987;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[78], attr, VSI_NN_TYPE_UINT8, 1431680, 32768);

    /* @Conv_Conv_136_53:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00013805330672767013;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[79], attr, VSI_NN_TYPE_INT32, 1431168, 512);

    /* @Conv_Conv_151_31:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.008450222201645374;
    attr.dtype.zero_point = 170;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[80], attr, VSI_NN_TYPE_UINT8, 1522816, 16384);

    /* @Conv_Conv_151_31:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001952024467755109;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[81], attr, VSI_NN_TYPE_INT32, 1522560, 256);

    /* @Conv_Conv_142_89:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006469979882240295;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[82], attr, VSI_NN_TYPE_UINT8, 1464704, 16384);

    /* @Conv_Conv_142_89:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014945831208024174;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[83], attr, VSI_NN_TYPE_INT32, 1464448, 256);

    /* @Conv_Conv_145_72:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.013424075208604336;
    attr.dtype.zero_point = 153;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[84], attr, VSI_NN_TYPE_UINT8, 1481344, 4096);

    /* @Conv_Conv_145_72:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014698713493999094;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[85], attr, VSI_NN_TYPE_INT32, 1481088, 256);

    /* @Conv_Conv_148_41:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.010776573792099953;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[86], attr, VSI_NN_TYPE_UINT8, 1485696, 36864);

    /* @Conv_Conv_148_41:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00012913580576423556;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[87], attr, VSI_NN_TYPE_INT32, 1485440, 256);

    /* @Conv_Conv_155_16:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.033583976328372955;
    attr.dtype.zero_point = 99;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[88], attr, VSI_NN_TYPE_UINT8, 1539712, 16384);

    /* @Conv_Conv_155_16:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0008047822047956288;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[89], attr, VSI_NN_TYPE_INT32, 1539200, 512);

    /* @Conv_Conv_198_8:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 255;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0037387025076895952;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[90], attr, VSI_NN_TYPE_UINT8, 3781884, 32640);

    /* @Conv_Conv_198_8:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 255;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002718106552492827;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[91], attr, VSI_NN_TYPE_INT32, 3780864, 1020);

    /* @Conv_Conv_158_68:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0018741065869107842;
    attr.dtype.zero_point = 106;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[92], attr, VSI_NN_TYPE_UINT8, 1556608, 147456);

    /* @Conv_Conv_158_68:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00013625103747472167;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[93], attr, VSI_NN_TYPE_INT32, 1556096, 512);

    /* @Conv_Conv_171_28:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009194305166602135;
    attr.dtype.zero_point = 156;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[94], attr, VSI_NN_TYPE_UINT8, 1904896, 32768);

    /* @Conv_Conv_171_28:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00021239096531644464;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[95], attr, VSI_NN_TYPE_INT32, 1904384, 512);

    /* @Conv_Conv_162_83:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007286927662789822;
    attr.dtype.zero_point = 147;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[96], attr, VSI_NN_TYPE_UINT8, 1704576, 32768);

    /* @Conv_Conv_162_83:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001683300215518102;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[97], attr, VSI_NN_TYPE_INT32, 1704064, 512);

    /* @Conv_Conv_165_66:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00856582261621952;
    attr.dtype.zero_point = 149;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[98], attr, VSI_NN_TYPE_UINT8, 1737856, 16384);

    /* @Conv_Conv_165_66:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001821627520257607;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[99], attr, VSI_NN_TYPE_INT32, 1737344, 512);

    /* @Conv_Conv_168_37:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007501648738980293;
    attr.dtype.zero_point = 151;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[100], attr, VSI_NN_TYPE_UINT8, 1754752, 147456);

    /* @Conv_Conv_168_37:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001464924425818026;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[101], attr, VSI_NN_TYPE_INT32, 1754240, 512);

    /* @Conv_Conv_175_14:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.017144285142421722;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[102], attr, VSI_NN_TYPE_UINT8, 1938688, 65536);

    /* @Conv_Conv_175_14:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0005362345254980028;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[103], attr, VSI_NN_TYPE_INT32, 1937664, 1024);

    /* @Conv_Conv_200_7:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 255;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0034323299769312143;
    attr.dtype.zero_point = 122;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[104], attr, VSI_NN_TYPE_UINT8, 3815544, 65280);

    /* @Conv_Conv_200_7:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 255;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002841722161974758;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[105], attr, VSI_NN_TYPE_INT32, 3814524, 1020);

    /* @Conv_Conv_178_62:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.002137536648660898;
    attr.dtype.zero_point = 105;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[106], attr, VSI_NN_TYPE_UINT8, 2005248, 589824);

    /* @Conv_Conv_178_62:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00017697265138849616;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[107], attr, VSI_NN_TYPE_INT32, 2004224, 1024);

    /* @Conv_Conv_191_25:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006345307920128107;
    attr.dtype.zero_point = 147;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[108], attr, VSI_NN_TYPE_UINT8, 3385600, 131072);

    /* @Conv_Conv_191_25:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00018158051534555852;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[109], attr, VSI_NN_TYPE_INT32, 3384576, 1024);

    /* @Conv_Conv_182_77:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.011167038232088089;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[110], attr, VSI_NN_TYPE_UINT8, 2596096, 131072);

    /* @Conv_Conv_182_77:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0003195615718141198;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[111], attr, VSI_NN_TYPE_INT32, 2595072, 1024);

    /* @Conv_Conv_185_60:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009258602745831013;
    attr.dtype.zero_point = 165;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[112], attr, VSI_NN_TYPE_UINT8, 2728192, 65536);

    /* @Conv_Conv_185_60:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00023569683253299445;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[113], attr, VSI_NN_TYPE_INT32, 2727168, 1024);

    /* @Conv_Conv_188_33:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005748922470957041;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[114], attr, VSI_NN_TYPE_UINT8, 2794752, 589824);

    /* @Conv_Conv_188_33:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014452678442467004;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[115], attr, VSI_NN_TYPE_INT32, 2793728, 1024);

    /* @Conv_Conv_195_12:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009458360262215137;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[116], attr, VSI_NN_TYPE_UINT8, 3518720, 262144);

    /* @Conv_Conv_195_12:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002684990467969328;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[117], attr, VSI_NN_TYPE_INT32, 3516672, 2048);

    /* @Conv_Conv_202_6:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 255;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0029813877772539854;
    attr.dtype.zero_point = 115;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[118], attr, VSI_NN_TYPE_UINT8, 3881844, 130560);

    /* @Conv_Conv_202_6:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 255;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016791610687505454;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[119], attr, VSI_NN_TYPE_INT32, 3880824, 1020);



    /* @Conv_Conv_0_190:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.2723581790924072;
    attr.dtype.zero_point = 126;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_1_191_Mul_Mul_2_175:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.13854044675827026;
    attr.dtype.zero_point = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_3_174:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.37591466307640076;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_4_160_Mul_Mul_5_159:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.18807700276374817;
    attr.dtype.zero_point = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_16_145:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.18296155333518982;
    attr.dtype.zero_point = 184;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_6_170:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.12421887367963791;
    attr.dtype.zero_point = 224;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_17_146_Mul_Mul_18_132:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05211292952299118;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_7_171_Mul_Mul_8_157:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.014856070280075073;
    attr.dtype.zero_point = 19;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_9_192:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.16258272528648376;
    attr.dtype.zero_point = 169;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_10_189_Mul_Mul_11_188:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.052253466099500656;
    attr.dtype.zero_point = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_12_172:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.10506204515695572;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_13_173_Mul_Mul_14_158:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04828434810042381;
    attr.dtype.zero_point = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_15_144:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05211292952299118;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_19_131:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05211292952299118;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_20_116:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08951818197965622;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_21_117_Mul_Mul_22_106:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03380062058568001;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_23_104:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05125468596816063;
    attr.dtype.zero_point = 152;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_24_105_Mul_Mul_25_93:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.01908816769719124;
    attr.dtype.zero_point = 15;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_43_80:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05107007548213005;
    attr.dtype.zero_point = 139;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_26_125:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024125250056385994;
    attr.dtype.zero_point = 171;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_44_79_Mul_Mul_45_76:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03105919063091278;
    attr.dtype.zero_point = 27;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_27_126_Mul_Mul_28_112:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.007221718318760395;
    attr.dtype.zero_point = 39;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_29_142:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04419032856822014;
    attr.dtype.zero_point = 125;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_30_143_Mul_Mul_31_130:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023556923493742943;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_32_127:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0378076508641243;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_33_128_Mul_Mul_34_113:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.013104261830449104;
    attr.dtype.zero_point = 21;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_35_101:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.014473071321845055;
    attr.dtype.zero_point = 38;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_36_129:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04977419972419739;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_37_115_Mul_Mul_38_114:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.021762048825621605;
    attr.dtype.zero_point = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_39_102:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.056121084839105606;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_40_103_Mul_Mul_41_92:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.025696629658341408;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_42_91:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03105919063091278;
    attr.dtype.zero_point = 27;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_46_75:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03105919063091278;
    attr.dtype.zero_point = 27;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_47_58:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05603272467851639;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_48_59_Mul_Mul_49_44:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023100273683667183;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_50_156:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06275808066129684;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_51_155_Mul_Mul_52_154:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022293444722890854;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_77_141:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.09070868045091629;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_53_201:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04401643946766853;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_78_140_Mul_Mul_79_139:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.042450107634067535;
    attr.dtype.zero_point = 26;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_54_202_Mul_Mul_55_196:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.013347957283258438;
    attr.dtype.zero_point = 21;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_56_204:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0910598635673523;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[41]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_57_203_Mul_Mul_58_200:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03469768911600113;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[42]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_59_199:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03535277023911476;
    attr.dtype.zero_point = 154;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[43]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_60_198_Mul_Mul_61_197:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.013913098722696304;
    attr.dtype.zero_point = 20;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[44]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_62_182:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.012564707547426224;
    attr.dtype.zero_point = 44;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[45]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_63_195:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0655536875128746;
    attr.dtype.zero_point = 116;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[46]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_64_193_Mul_Mul_65_187:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03691719472408295;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[47]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_66_186:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.046652551740407944;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[48]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_67_185_Mul_Mul_68_183:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023959364742040634;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[49]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_69_165:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02831471711397171;
    attr.dtype.zero_point = 30;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[50]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_70_184:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06435766816139221;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[51]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_71_169_Mul_Mul_72_168:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03265931084752083;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[52]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_73_166:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06783705204725266;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[53]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_74_167_Mul_Mul_75_153:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.033171672374010086;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[54]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_76_152:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.042450107634067535;
    attr.dtype.zero_point = 26;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[55]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_80_138:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.042450107634067535;
    attr.dtype.zero_point = 26;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[56]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_81_123:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.048300601541996;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[57]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_82_124_Mul_Mul_83_111:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02861650101840496;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[58]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_84_163:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06344740092754364;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[59]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_85_164_Mul_Mul_86_151:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02887936867773533;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[60]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_97_148:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06750302016735077;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[61]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_87_176:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04125317558646202;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[62]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_98_149_Mul_Mul_99_134:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03686188533902168;
    attr.dtype.zero_point = 15;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[63]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_88_177_Mul_Mul_89_161:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02008051611483097;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[64]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_90_194:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06624585390090942;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[65]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_91_181_Mul_Mul_92_180:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03407321870326996;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[66]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_93_178:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06496977061033249;
    attr.dtype.zero_point = 132;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[67]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_94_179_Mul_Mul_95_162:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03236629068851471;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[68]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Add_Add_96_147:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03686188533902168;
    attr.dtype.zero_point = 15;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[69]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_100_133:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03686188533902168;
    attr.dtype.zero_point = 15;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[70]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_101_118:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06977716833353043;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[71]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_102_119_Mul_Mul_103_107:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.030367475003004074;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[72]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_104_97:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03463790565729141;
    attr.dtype.zero_point = 93;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[73]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_105_96_Mul_Mul_106_94:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0230373777449131;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[74]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MaxPool_MaxPool_107_95:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0230373777449131;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[75]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MaxPool_MaxPool_108_86:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0230373777449131;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[76]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @MaxPool_MaxPool_109_85:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0230373777449131;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[77]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_110_82:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0230373777449131;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[78]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_111_81:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.041002556681632996;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[79]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_112_65_Mul_Mul_113_64:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02053912542760372;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[80]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_114_48:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.046048130840063095;
    attr.dtype.zero_point = 139;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[81]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_115_49_Mul_Mul_116_36:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02861650101840496;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[82]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Resize_Resize_118_122:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02861650101840496;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[83]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_119_110:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02861650101840496;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[84]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_129_99:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03674067184329033;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[85]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_120_150:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04375503957271576;
    attr.dtype.zero_point = 149;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[86]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_130_100_Mul_Mul_131_90:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022176841273903847;
    attr.dtype.zero_point = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[87]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_121_137_Mul_Mul_122_136:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.019134489819407463;
    attr.dtype.zero_point = 15;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[88]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_123_135:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04327625408768654;
    attr.dtype.zero_point = 141;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[89]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_124_121_Mul_Mul_125_120:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020220831036567688;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[90]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_126_108:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04481174424290657;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[91]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_127_109_Mul_Mul_128_98:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022176841273903847;
    attr.dtype.zero_point = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[92]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_132_88:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022176841273903847;
    attr.dtype.zero_point = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[93]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_133_87:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.052195433527231216;
    attr.dtype.zero_point = 126;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[94]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_134_71_Mul_Mul_135_70:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.027509167790412903;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[95]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_136_53:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.039364613592624664;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[96]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_137_54_Mul_Mul_138_40:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023100273683667183;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[97]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Resize_Resize_140_57:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023100273683667183;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[98]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_141_43:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023100273683667183;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[99]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_151_31:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0518367700278759;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[100]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_142_89:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.027583619579672813;
    attr.dtype.zero_point = 146;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[101]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_152_32_Mul_Mul_153_23:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023963280022144318;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[102]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_143_74_Mul_Mul_144_73:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.010949516668915749;
    attr.dtype.zero_point = 25;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[103]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_145_72:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02936498634517193;
    attr.dtype.zero_point = 155;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[104]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_146_56_Mul_Mul_147_55:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.011983010917901993;
    attr.dtype.zero_point = 23;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[105]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_148_41:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05295274034142494;
    attr.dtype.zero_point = 129;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[106]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_149_42_Mul_Mul_150_30:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023963280022144318;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[107]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_154_22:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023963280022144318;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[108]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_155_16:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.1261356920003891;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[109]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_156_17_Mul_Mul_157_11:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.07270186394453049;
    attr.dtype.zero_point = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[110]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_158_68:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.045252855867147446;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[112]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_159_69_Mul_Mul_160_52:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023100273683667183;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[113]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_161_39:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023100273683667183;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[114]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_171_28:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.035293083637952805;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[115]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_162_83:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.047906335443258286;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[116]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_172_29_Mul_Mul_173_21:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.031277742236852646;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[117]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_163_84_Mul_Mul_164_67:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.021266229450702667;
    attr.dtype.zero_point = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[118]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_165_66:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.050273455679416656;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[119]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_166_51_Mul_Mul_167_50:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.019528033211827278;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[120]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_168_37:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.09444527328014374;
    attr.dtype.zero_point = 173;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[121]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_169_38_Mul_Mul_170_27:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.031277742236852646;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[122]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_174_20:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.031277742236852646;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[123]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_175_14:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.14543484151363373;
    attr.dtype.zero_point = 112;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[124]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_176_15_Mul_Mul_177_10:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08279280364513397;
    attr.dtype.zero_point = 3;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[125]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_178_62:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06275603920221329;
    attr.dtype.zero_point = 143;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[127]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_179_63_Mul_Mul_180_47:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02861650101840496;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[128]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_181_35:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02861650101840496;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[129]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_191_25:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.045508529990911484;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[130]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_182_77:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06247211620211601;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[131]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_192_26_Mul_Mul_193_19:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.028387485072016716;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[132]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_183_78_Mul_Mul_184_61:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02545706368982792;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[133]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_185_60:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06519127637147903;
    attr.dtype.zero_point = 161;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[134]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_186_46_Mul_Mul_187_45:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.025139804929494858;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[135]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_188_33:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08355940133333206;
    attr.dtype.zero_point = 172;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[136]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_189_34_Mul_Mul_190_24:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.028387485072016716;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[137]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Concat_Concat_194_18:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.028387485072016716;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[138]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Conv_Conv_195_12:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.10490881651639938;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[139]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @Sigmoid_Sigmoid_196_13_Mul_Mul_197_9:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05632145702838898;
    attr.dtype.zero_point = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[140]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[0]->input.tensors[0] = norm_tensor[3];
    node[111]->output.tensors[0] = norm_tensor[0];
    node[126]->output.tensors[0] = norm_tensor[1];
    node[141]->output.tensors[0] = norm_tensor[2];

    /* Conv_Conv_0_190 */
    node[0]->input.tensors[1] = const_tensor[0]; /* data_weight */
    node[0]->input.tensors[2] = const_tensor[1]; /* data_bias */

    /* Sigmoid_Sigmoid_1_191_Mul_Mul_2_175 */
    node[1]->input.tensors[0] = node[0]->output.tensors[0];

    /* Conv_Conv_3_174 */
    node[2]->input.tensors[0] = node[1]->output.tensors[0];
    node[2]->input.tensors[1] = const_tensor[2]; /* data_weight */
    node[2]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* Sigmoid_Sigmoid_4_160_Mul_Mul_5_159 */
    node[3]->input.tensors[0] = node[2]->output.tensors[0];

    /* Conv_Conv_16_145 */
    node[4]->input.tensors[0] = node[3]->output.tensors[0];
    node[4]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[4]->input.tensors[2] = const_tensor[5]; /* data_bias */

    /* Conv_Conv_6_170 */
    node[5]->input.tensors[0] = node[3]->output.tensors[0];
    node[5]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[5]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* Sigmoid_Sigmoid_17_146_Mul_Mul_18_132 */
    node[6]->input.tensors[0] = node[4]->output.tensors[0];

    /* Sigmoid_Sigmoid_7_171_Mul_Mul_8_157 */
    node[7]->input.tensors[0] = node[5]->output.tensors[0];

    /* Conv_Conv_9_192 */
    node[8]->input.tensors[0] = node[7]->output.tensors[0];
    node[8]->input.tensors[1] = const_tensor[8]; /* data_weight */
    node[8]->input.tensors[2] = const_tensor[9]; /* data_bias */

    /* Sigmoid_Sigmoid_10_189_Mul_Mul_11_188 */
    node[9]->input.tensors[0] = node[8]->output.tensors[0];

    /* Conv_Conv_12_172 */
    node[10]->input.tensors[0] = node[9]->output.tensors[0];
    node[10]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[10]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* Sigmoid_Sigmoid_13_173_Mul_Mul_14_158 */
    node[11]->input.tensors[0] = node[10]->output.tensors[0];

    /* Add_Add_15_144 */
    node[12]->input.tensors[0] = node[7]->output.tensors[0];
    node[12]->input.tensors[1] = node[11]->output.tensors[0];

    /* Concat_Concat_19_131 */
    node[13]->input.tensors[0] = node[12]->output.tensors[0];
    node[13]->input.tensors[1] = node[6]->output.tensors[0];

    /* Conv_Conv_20_116 */
    node[14]->input.tensors[0] = node[13]->output.tensors[0];
    node[14]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[14]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* Sigmoid_Sigmoid_21_117_Mul_Mul_22_106 */
    node[15]->input.tensors[0] = node[14]->output.tensors[0];

    /* Conv_Conv_23_104 */
    node[16]->input.tensors[0] = node[15]->output.tensors[0];
    node[16]->input.tensors[1] = const_tensor[14]; /* data_weight */
    node[16]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* Sigmoid_Sigmoid_24_105_Mul_Mul_25_93 */
    node[17]->input.tensors[0] = node[16]->output.tensors[0];

    /* Conv_Conv_43_80 */
    node[18]->input.tensors[0] = node[17]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[18]->input.tensors[2] = const_tensor[17]; /* data_bias */

    /* Conv_Conv_26_125 */
    node[19]->input.tensors[0] = node[17]->output.tensors[0];
    node[19]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[19]->input.tensors[2] = const_tensor[19]; /* data_bias */

    /* Sigmoid_Sigmoid_44_79_Mul_Mul_45_76 */
    node[20]->input.tensors[0] = node[18]->output.tensors[0];

    /* Sigmoid_Sigmoid_27_126_Mul_Mul_28_112 */
    node[21]->input.tensors[0] = node[19]->output.tensors[0];

    /* Conv_Conv_29_142 */
    node[22]->input.tensors[0] = node[21]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* Sigmoid_Sigmoid_30_143_Mul_Mul_31_130 */
    node[23]->input.tensors[0] = node[22]->output.tensors[0];

    /* Conv_Conv_32_127 */
    node[24]->input.tensors[0] = node[23]->output.tensors[0];
    node[24]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[24]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* Sigmoid_Sigmoid_33_128_Mul_Mul_34_113 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];

    /* Add_Add_35_101 */
    node[26]->input.tensors[0] = node[21]->output.tensors[0];
    node[26]->input.tensors[1] = node[25]->output.tensors[0];

    /* Conv_Conv_36_129 */
    node[27]->input.tensors[0] = node[26]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[24]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[25]; /* data_bias */

    /* Sigmoid_Sigmoid_37_115_Mul_Mul_38_114 */
    node[28]->input.tensors[0] = node[27]->output.tensors[0];

    /* Conv_Conv_39_102 */
    node[29]->input.tensors[0] = node[28]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[26]; /* data_weight */
    node[29]->input.tensors[2] = const_tensor[27]; /* data_bias */

    /* Sigmoid_Sigmoid_40_103_Mul_Mul_41_92 */
    node[30]->input.tensors[0] = node[29]->output.tensors[0];

    /* Add_Add_42_91 */
    node[31]->input.tensors[0] = node[26]->output.tensors[0];
    node[31]->input.tensors[1] = node[30]->output.tensors[0];

    /* Concat_Concat_46_75 */
    node[32]->input.tensors[0] = node[31]->output.tensors[0];
    node[32]->input.tensors[1] = node[20]->output.tensors[0];

    /* Conv_Conv_47_58 */
    node[33]->input.tensors[0] = node[32]->output.tensors[0];
    node[33]->input.tensors[1] = const_tensor[28]; /* data_weight */
    node[33]->input.tensors[2] = const_tensor[29]; /* data_bias */

    /* Sigmoid_Sigmoid_48_59_Mul_Mul_49_44 */
    node[34]->input.tensors[0] = node[33]->output.tensors[0];

    /* Conv_Conv_50_156 */
    node[35]->input.tensors[0] = node[34]->output.tensors[0];
    node[35]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[35]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* Sigmoid_Sigmoid_51_155_Mul_Mul_52_154 */
    node[36]->input.tensors[0] = node[35]->output.tensors[0];

    /* Conv_Conv_77_141 */
    node[37]->input.tensors[0] = node[36]->output.tensors[0];
    node[37]->input.tensors[1] = const_tensor[32]; /* data_weight */
    node[37]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* Conv_Conv_53_201 */
    node[38]->input.tensors[0] = node[36]->output.tensors[0];
    node[38]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[38]->input.tensors[2] = const_tensor[35]; /* data_bias */

    /* Sigmoid_Sigmoid_78_140_Mul_Mul_79_139 */
    node[39]->input.tensors[0] = node[37]->output.tensors[0];

    /* Sigmoid_Sigmoid_54_202_Mul_Mul_55_196 */
    node[40]->input.tensors[0] = node[38]->output.tensors[0];

    /* Conv_Conv_56_204 */
    node[41]->input.tensors[0] = node[40]->output.tensors[0];
    node[41]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[41]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* Sigmoid_Sigmoid_57_203_Mul_Mul_58_200 */
    node[42]->input.tensors[0] = node[41]->output.tensors[0];

    /* Conv_Conv_59_199 */
    node[43]->input.tensors[0] = node[42]->output.tensors[0];
    node[43]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[43]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* Sigmoid_Sigmoid_60_198_Mul_Mul_61_197 */
    node[44]->input.tensors[0] = node[43]->output.tensors[0];

    /* Add_Add_62_182 */
    node[45]->input.tensors[0] = node[40]->output.tensors[0];
    node[45]->input.tensors[1] = node[44]->output.tensors[0];

    /* Conv_Conv_63_195 */
    node[46]->input.tensors[0] = node[45]->output.tensors[0];
    node[46]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[46]->input.tensors[2] = const_tensor[41]; /* data_bias */

    /* Sigmoid_Sigmoid_64_193_Mul_Mul_65_187 */
    node[47]->input.tensors[0] = node[46]->output.tensors[0];

    /* Conv_Conv_66_186 */
    node[48]->input.tensors[0] = node[47]->output.tensors[0];
    node[48]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[48]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* Sigmoid_Sigmoid_67_185_Mul_Mul_68_183 */
    node[49]->input.tensors[0] = node[48]->output.tensors[0];

    /* Add_Add_69_165 */
    node[50]->input.tensors[0] = node[45]->output.tensors[0];
    node[50]->input.tensors[1] = node[49]->output.tensors[0];

    /* Conv_Conv_70_184 */
    node[51]->input.tensors[0] = node[50]->output.tensors[0];
    node[51]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[51]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* Sigmoid_Sigmoid_71_169_Mul_Mul_72_168 */
    node[52]->input.tensors[0] = node[51]->output.tensors[0];

    /* Conv_Conv_73_166 */
    node[53]->input.tensors[0] = node[52]->output.tensors[0];
    node[53]->input.tensors[1] = const_tensor[46]; /* data_weight */
    node[53]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* Sigmoid_Sigmoid_74_167_Mul_Mul_75_153 */
    node[54]->input.tensors[0] = node[53]->output.tensors[0];

    /* Add_Add_76_152 */
    node[55]->input.tensors[0] = node[50]->output.tensors[0];
    node[55]->input.tensors[1] = node[54]->output.tensors[0];

    /* Concat_Concat_80_138 */
    node[56]->input.tensors[0] = node[55]->output.tensors[0];
    node[56]->input.tensors[1] = node[39]->output.tensors[0];

    /* Conv_Conv_81_123 */
    node[57]->input.tensors[0] = node[56]->output.tensors[0];
    node[57]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[57]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* Sigmoid_Sigmoid_82_124_Mul_Mul_83_111 */
    node[58]->input.tensors[0] = node[57]->output.tensors[0];

    /* Conv_Conv_84_163 */
    node[59]->input.tensors[0] = node[58]->output.tensors[0];
    node[59]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[59]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* Sigmoid_Sigmoid_85_164_Mul_Mul_86_151 */
    node[60]->input.tensors[0] = node[59]->output.tensors[0];

    /* Conv_Conv_97_148 */
    node[61]->input.tensors[0] = node[60]->output.tensors[0];
    node[61]->input.tensors[1] = const_tensor[52]; /* data_weight */
    node[61]->input.tensors[2] = const_tensor[53]; /* data_bias */

    /* Conv_Conv_87_176 */
    node[62]->input.tensors[0] = node[60]->output.tensors[0];
    node[62]->input.tensors[1] = const_tensor[54]; /* data_weight */
    node[62]->input.tensors[2] = const_tensor[55]; /* data_bias */

    /* Sigmoid_Sigmoid_98_149_Mul_Mul_99_134 */
    node[63]->input.tensors[0] = node[61]->output.tensors[0];

    /* Sigmoid_Sigmoid_88_177_Mul_Mul_89_161 */
    node[64]->input.tensors[0] = node[62]->output.tensors[0];

    /* Conv_Conv_90_194 */
    node[65]->input.tensors[0] = node[64]->output.tensors[0];
    node[65]->input.tensors[1] = const_tensor[56]; /* data_weight */
    node[65]->input.tensors[2] = const_tensor[57]; /* data_bias */

    /* Sigmoid_Sigmoid_91_181_Mul_Mul_92_180 */
    node[66]->input.tensors[0] = node[65]->output.tensors[0];

    /* Conv_Conv_93_178 */
    node[67]->input.tensors[0] = node[66]->output.tensors[0];
    node[67]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[67]->input.tensors[2] = const_tensor[59]; /* data_bias */

    /* Sigmoid_Sigmoid_94_179_Mul_Mul_95_162 */
    node[68]->input.tensors[0] = node[67]->output.tensors[0];

    /* Add_Add_96_147 */
    node[69]->input.tensors[0] = node[64]->output.tensors[0];
    node[69]->input.tensors[1] = node[68]->output.tensors[0];

    /* Concat_Concat_100_133 */
    node[70]->input.tensors[0] = node[69]->output.tensors[0];
    node[70]->input.tensors[1] = node[63]->output.tensors[0];

    /* Conv_Conv_101_118 */
    node[71]->input.tensors[0] = node[70]->output.tensors[0];
    node[71]->input.tensors[1] = const_tensor[60]; /* data_weight */
    node[71]->input.tensors[2] = const_tensor[61]; /* data_bias */

    /* Sigmoid_Sigmoid_102_119_Mul_Mul_103_107 */
    node[72]->input.tensors[0] = node[71]->output.tensors[0];

    /* Conv_Conv_104_97 */
    node[73]->input.tensors[0] = node[72]->output.tensors[0];
    node[73]->input.tensors[1] = const_tensor[62]; /* data_weight */
    node[73]->input.tensors[2] = const_tensor[63]; /* data_bias */

    /* Sigmoid_Sigmoid_105_96_Mul_Mul_106_94 */
    node[74]->input.tensors[0] = node[73]->output.tensors[0];

    /* MaxPool_MaxPool_107_95 */
    node[75]->input.tensors[0] = node[74]->output.tensors[0];

    /* MaxPool_MaxPool_108_86 */
    node[76]->input.tensors[0] = node[75]->output.tensors[0];

    /* MaxPool_MaxPool_109_85 */
    node[77]->input.tensors[0] = node[76]->output.tensors[0];

    /* Concat_Concat_110_82 */
    node[78]->input.tensors[0] = node[74]->output.tensors[0];
    node[78]->input.tensors[1] = node[75]->output.tensors[0];
    node[78]->input.tensors[2] = node[76]->output.tensors[0];
    node[78]->input.tensors[3] = node[77]->output.tensors[0];

    /* Conv_Conv_111_81 */
    node[79]->input.tensors[0] = node[78]->output.tensors[0];
    node[79]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[79]->input.tensors[2] = const_tensor[65]; /* data_bias */

    /* Sigmoid_Sigmoid_112_65_Mul_Mul_113_64 */
    node[80]->input.tensors[0] = node[79]->output.tensors[0];

    /* Conv_Conv_114_48 */
    node[81]->input.tensors[0] = node[80]->output.tensors[0];
    node[81]->input.tensors[1] = const_tensor[66]; /* data_weight */
    node[81]->input.tensors[2] = const_tensor[67]; /* data_bias */

    /* Sigmoid_Sigmoid_115_49_Mul_Mul_116_36 */
    node[82]->input.tensors[0] = node[81]->output.tensors[0];

    /* Resize_Resize_118_122 */
    node[83]->input.tensors[0] = node[82]->output.tensors[0];

    /* Concat_Concat_119_110 */
    node[84]->input.tensors[0] = node[83]->output.tensors[0];
    node[84]->input.tensors[1] = node[58]->output.tensors[0];

    /* Conv_Conv_129_99 */
    node[85]->input.tensors[0] = node[84]->output.tensors[0];
    node[85]->input.tensors[1] = const_tensor[68]; /* data_weight */
    node[85]->input.tensors[2] = const_tensor[69]; /* data_bias */

    /* Conv_Conv_120_150 */
    node[86]->input.tensors[0] = node[84]->output.tensors[0];
    node[86]->input.tensors[1] = const_tensor[70]; /* data_weight */
    node[86]->input.tensors[2] = const_tensor[71]; /* data_bias */

    /* Sigmoid_Sigmoid_130_100_Mul_Mul_131_90 */
    node[87]->input.tensors[0] = node[85]->output.tensors[0];

    /* Sigmoid_Sigmoid_121_137_Mul_Mul_122_136 */
    node[88]->input.tensors[0] = node[86]->output.tensors[0];

    /* Conv_Conv_123_135 */
    node[89]->input.tensors[0] = node[88]->output.tensors[0];
    node[89]->input.tensors[1] = const_tensor[72]; /* data_weight */
    node[89]->input.tensors[2] = const_tensor[73]; /* data_bias */

    /* Sigmoid_Sigmoid_124_121_Mul_Mul_125_120 */
    node[90]->input.tensors[0] = node[89]->output.tensors[0];

    /* Conv_Conv_126_108 */
    node[91]->input.tensors[0] = node[90]->output.tensors[0];
    node[91]->input.tensors[1] = const_tensor[74]; /* data_weight */
    node[91]->input.tensors[2] = const_tensor[75]; /* data_bias */

    /* Sigmoid_Sigmoid_127_109_Mul_Mul_128_98 */
    node[92]->input.tensors[0] = node[91]->output.tensors[0];

    /* Concat_Concat_132_88 */
    node[93]->input.tensors[0] = node[92]->output.tensors[0];
    node[93]->input.tensors[1] = node[87]->output.tensors[0];

    /* Conv_Conv_133_87 */
    node[94]->input.tensors[0] = node[93]->output.tensors[0];
    node[94]->input.tensors[1] = const_tensor[76]; /* data_weight */
    node[94]->input.tensors[2] = const_tensor[77]; /* data_bias */

    /* Sigmoid_Sigmoid_134_71_Mul_Mul_135_70 */
    node[95]->input.tensors[0] = node[94]->output.tensors[0];

    /* Conv_Conv_136_53 */
    node[96]->input.tensors[0] = node[95]->output.tensors[0];
    node[96]->input.tensors[1] = const_tensor[78]; /* data_weight */
    node[96]->input.tensors[2] = const_tensor[79]; /* data_bias */

    /* Sigmoid_Sigmoid_137_54_Mul_Mul_138_40 */
    node[97]->input.tensors[0] = node[96]->output.tensors[0];

    /* Resize_Resize_140_57 */
    node[98]->input.tensors[0] = node[97]->output.tensors[0];

    /* Concat_Concat_141_43 */
    node[99]->input.tensors[0] = node[98]->output.tensors[0];
    node[99]->input.tensors[1] = node[34]->output.tensors[0];

    /* Conv_Conv_151_31 */
    node[100]->input.tensors[0] = node[99]->output.tensors[0];
    node[100]->input.tensors[1] = const_tensor[80]; /* data_weight */
    node[100]->input.tensors[2] = const_tensor[81]; /* data_bias */

    /* Conv_Conv_142_89 */
    node[101]->input.tensors[0] = node[99]->output.tensors[0];
    node[101]->input.tensors[1] = const_tensor[82]; /* data_weight */
    node[101]->input.tensors[2] = const_tensor[83]; /* data_bias */

    /* Sigmoid_Sigmoid_152_32_Mul_Mul_153_23 */
    node[102]->input.tensors[0] = node[100]->output.tensors[0];

    /* Sigmoid_Sigmoid_143_74_Mul_Mul_144_73 */
    node[103]->input.tensors[0] = node[101]->output.tensors[0];

    /* Conv_Conv_145_72 */
    node[104]->input.tensors[0] = node[103]->output.tensors[0];
    node[104]->input.tensors[1] = const_tensor[84]; /* data_weight */
    node[104]->input.tensors[2] = const_tensor[85]; /* data_bias */

    /* Sigmoid_Sigmoid_146_56_Mul_Mul_147_55 */
    node[105]->input.tensors[0] = node[104]->output.tensors[0];

    /* Conv_Conv_148_41 */
    node[106]->input.tensors[0] = node[105]->output.tensors[0];
    node[106]->input.tensors[1] = const_tensor[86]; /* data_weight */
    node[106]->input.tensors[2] = const_tensor[87]; /* data_bias */

    /* Sigmoid_Sigmoid_149_42_Mul_Mul_150_30 */
    node[107]->input.tensors[0] = node[106]->output.tensors[0];

    /* Concat_Concat_154_22 */
    node[108]->input.tensors[0] = node[107]->output.tensors[0];
    node[108]->input.tensors[1] = node[102]->output.tensors[0];

    /* Conv_Conv_155_16 */
    node[109]->input.tensors[0] = node[108]->output.tensors[0];
    node[109]->input.tensors[1] = const_tensor[88]; /* data_weight */
    node[109]->input.tensors[2] = const_tensor[89]; /* data_bias */

    /* Sigmoid_Sigmoid_156_17_Mul_Mul_157_11 */
    node[110]->input.tensors[0] = node[109]->output.tensors[0];

    /* Conv_Conv_198_8 */
    node[111]->input.tensors[0] = node[110]->output.tensors[0];
    node[111]->input.tensors[1] = const_tensor[90]; /* data_weight */
    node[111]->input.tensors[2] = const_tensor[91]; /* data_bias */

    /* Conv_Conv_158_68 */
    node[112]->input.tensors[0] = node[110]->output.tensors[0];
    node[112]->input.tensors[1] = const_tensor[92]; /* data_weight */
    node[112]->input.tensors[2] = const_tensor[93]; /* data_bias */

    /* Sigmoid_Sigmoid_159_69_Mul_Mul_160_52 */
    node[113]->input.tensors[0] = node[112]->output.tensors[0];

    /* Concat_Concat_161_39 */
    node[114]->input.tensors[0] = node[113]->output.tensors[0];
    node[114]->input.tensors[1] = node[97]->output.tensors[0];

    /* Conv_Conv_171_28 */
    node[115]->input.tensors[0] = node[114]->output.tensors[0];
    node[115]->input.tensors[1] = const_tensor[94]; /* data_weight */
    node[115]->input.tensors[2] = const_tensor[95]; /* data_bias */

    /* Conv_Conv_162_83 */
    node[116]->input.tensors[0] = node[114]->output.tensors[0];
    node[116]->input.tensors[1] = const_tensor[96]; /* data_weight */
    node[116]->input.tensors[2] = const_tensor[97]; /* data_bias */

    /* Sigmoid_Sigmoid_172_29_Mul_Mul_173_21 */
    node[117]->input.tensors[0] = node[115]->output.tensors[0];

    /* Sigmoid_Sigmoid_163_84_Mul_Mul_164_67 */
    node[118]->input.tensors[0] = node[116]->output.tensors[0];

    /* Conv_Conv_165_66 */
    node[119]->input.tensors[0] = node[118]->output.tensors[0];
    node[119]->input.tensors[1] = const_tensor[98]; /* data_weight */
    node[119]->input.tensors[2] = const_tensor[99]; /* data_bias */

    /* Sigmoid_Sigmoid_166_51_Mul_Mul_167_50 */
    node[120]->input.tensors[0] = node[119]->output.tensors[0];

    /* Conv_Conv_168_37 */
    node[121]->input.tensors[0] = node[120]->output.tensors[0];
    node[121]->input.tensors[1] = const_tensor[100]; /* data_weight */
    node[121]->input.tensors[2] = const_tensor[101]; /* data_bias */

    /* Sigmoid_Sigmoid_169_38_Mul_Mul_170_27 */
    node[122]->input.tensors[0] = node[121]->output.tensors[0];

    /* Concat_Concat_174_20 */
    node[123]->input.tensors[0] = node[122]->output.tensors[0];
    node[123]->input.tensors[1] = node[117]->output.tensors[0];

    /* Conv_Conv_175_14 */
    node[124]->input.tensors[0] = node[123]->output.tensors[0];
    node[124]->input.tensors[1] = const_tensor[102]; /* data_weight */
    node[124]->input.tensors[2] = const_tensor[103]; /* data_bias */

    /* Sigmoid_Sigmoid_176_15_Mul_Mul_177_10 */
    node[125]->input.tensors[0] = node[124]->output.tensors[0];

    /* Conv_Conv_200_7 */
    node[126]->input.tensors[0] = node[125]->output.tensors[0];
    node[126]->input.tensors[1] = const_tensor[104]; /* data_weight */
    node[126]->input.tensors[2] = const_tensor[105]; /* data_bias */

    /* Conv_Conv_178_62 */
    node[127]->input.tensors[0] = node[125]->output.tensors[0];
    node[127]->input.tensors[1] = const_tensor[106]; /* data_weight */
    node[127]->input.tensors[2] = const_tensor[107]; /* data_bias */

    /* Sigmoid_Sigmoid_179_63_Mul_Mul_180_47 */
    node[128]->input.tensors[0] = node[127]->output.tensors[0];

    /* Concat_Concat_181_35 */
    node[129]->input.tensors[0] = node[128]->output.tensors[0];
    node[129]->input.tensors[1] = node[82]->output.tensors[0];

    /* Conv_Conv_191_25 */
    node[130]->input.tensors[0] = node[129]->output.tensors[0];
    node[130]->input.tensors[1] = const_tensor[108]; /* data_weight */
    node[130]->input.tensors[2] = const_tensor[109]; /* data_bias */

    /* Conv_Conv_182_77 */
    node[131]->input.tensors[0] = node[129]->output.tensors[0];
    node[131]->input.tensors[1] = const_tensor[110]; /* data_weight */
    node[131]->input.tensors[2] = const_tensor[111]; /* data_bias */

    /* Sigmoid_Sigmoid_192_26_Mul_Mul_193_19 */
    node[132]->input.tensors[0] = node[130]->output.tensors[0];

    /* Sigmoid_Sigmoid_183_78_Mul_Mul_184_61 */
    node[133]->input.tensors[0] = node[131]->output.tensors[0];

    /* Conv_Conv_185_60 */
    node[134]->input.tensors[0] = node[133]->output.tensors[0];
    node[134]->input.tensors[1] = const_tensor[112]; /* data_weight */
    node[134]->input.tensors[2] = const_tensor[113]; /* data_bias */

    /* Sigmoid_Sigmoid_186_46_Mul_Mul_187_45 */
    node[135]->input.tensors[0] = node[134]->output.tensors[0];

    /* Conv_Conv_188_33 */
    node[136]->input.tensors[0] = node[135]->output.tensors[0];
    node[136]->input.tensors[1] = const_tensor[114]; /* data_weight */
    node[136]->input.tensors[2] = const_tensor[115]; /* data_bias */

    /* Sigmoid_Sigmoid_189_34_Mul_Mul_190_24 */
    node[137]->input.tensors[0] = node[136]->output.tensors[0];

    /* Concat_Concat_194_18 */
    node[138]->input.tensors[0] = node[137]->output.tensors[0];
    node[138]->input.tensors[1] = node[132]->output.tensors[0];

    /* Conv_Conv_195_12 */
    node[139]->input.tensors[0] = node[138]->output.tensors[0];
    node[139]->input.tensors[1] = const_tensor[116]; /* data_weight */
    node[139]->input.tensors[2] = const_tensor[117]; /* data_bias */

    /* Sigmoid_Sigmoid_196_13_Mul_Mul_197_9 */
    node[140]->input.tensors[0] = node[139]->output.tensors[0];

    /* Conv_Conv_202_6 */
    node[141]->input.tensors[0] = node[140]->output.tensors[0];
    node[141]->input.tensors[1] = const_tensor[118]; /* data_weight */
    node[141]->input.tensors[2] = const_tensor[119]; /* data_bias */


    }
    else
    {
    node[0]->output.tensors[0] = norm_tensor[0];
    node[0]->output.tensors[1] = norm_tensor[1];
    node[0]->output.tensors[2] = norm_tensor[2];
    node[0]->input.tensors[0] = norm_tensor[3];

    }
    graph->output.tensors[0] = norm_tensor[0];
    graph->output.tensors[1] = norm_tensor[1];
    graph->output.tensors[2] = norm_tensor[2];
    graph->input.tensors[0] = norm_tensor[3];


    if( enable_pre_post_process )
    {
        sort = TRUE;
        if( pre_process_map_count > 0 )
        {
            for( i = 0; i < pre_process_map_count; i++ )
            {
                status = vsi_nn_AddGraphPreProcess(graph, pre_process_map[i].graph_input_idx,
                                                   pre_process_map[i].preprocesses,
                                                   pre_process_map[i].preprocess_count);
                TEST_CHECK_STATUS( status, error );
            }
        }

        if( post_process_map_count > 0 )
        {
            for( i = 0; i < post_process_map_count; i++ )
            {
                 status = vsi_nn_AddGraphPostProcess(graph, post_process_map[i].graph_output_idx,
                                                     post_process_map[i].postprocesses,
                                                     post_process_map[i].postprocess_count);
                 TEST_CHECK_STATUS( status, error );
            }
        }
    }

    status = vsi_nn_SetupGraph( graph, sort );
    TEST_CHECK_STATUS( status, error );
    vsi_nn_DumpGraphToJson( graph );

    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vsi_nn_DumpGraphToJson( graph );
    vnn_ReleaseYolov5sUint8( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateYolov5sUint8() */

void vnn_ReleaseYolov5sUint8
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseYolov5sUint8() */

