#pragma OPENCL EXTENSION cl_viv_vx_extension : enable

#include "cl_viv_vx_ext.h"

_viv_uniform VXC_512Bits uniLeakyReluInt8Lo_2x8b;
_viv_uniform VXC_512Bits uniLeakyReluInt8Hi_2x8b;
_viv_uniform VXC_512Bits uniLeakyReluInt16_2x8b;
_viv_uniform VXC_512Bits uniLeakyReluInt8_2x8;
_viv_uniform VXC_512Bits uniLeakyReluInt16_4x4;
_viv_uniform VXC_512Bits uniMergeMultiplier_2x8;
_viv_uniform int multiplier;
#if (VX_VERSION==2)
__kernel void leakyRelu_I8toI8_opt0
(
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
)
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));

    vxc_char16 in, dst;
    vxc_char32 src;
    VXC_ReadImage(in, input, coord.xy, 0, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    src.hi = max(in, 0);
    src.lo = min(in, 0);

    VXC_DP2x8_b(dst, src.hi, src.lo, alpha_hlf, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt8Lo_2x8b);
    VXC_DP2x8_b(dst, src.hi, src.lo, alpha_hlf, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt8Hi_2x8b);
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0));
}

__kernel void leakyRelu_I8toI8_opt1
(
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
)
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));

    vxc_char16 in, dst;
    vxc_char32 src;
    vxc_half8 paraHlf;
    VXC_ReadImage(in, input, coord.xy, 0, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    src.hi = max(in, 0);
    src.lo = min(in, 0);

    unsigned short src2;
    _viv_asm(COPY, src2, multiplier, 2);
    VXC_DP2x8(paraHlf, alpha_hlf, src2, VXC_MODIFIER(0, 1, 0, VXC_RM_TowardZero, 0), uniMergeMultiplier_2x8);
    VXC_DP2x8_b(dst, src.hi, src.lo, paraHlf, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt8Lo_2x8b);
    VXC_DP2x8_b(dst, src.hi, src.lo, paraHlf, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt8Hi_2x8b);
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0));
}

__kernel void leakyRelu_I16toI16_opt
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
    )
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));

    vxc_short8 in, dst;
    vxc_short16 src;
    VXC_ReadImage(in, input, coord.xy, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    src.hi = max(in, 0);
    src.lo = min(in, 0);
    VXC_DP2x8_b(dst, src.hi, src.lo, alpha_hlf, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt16_2x8b);
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
}

__kernel void leakyRelu_I16toI16_opt1
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
    )
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));

    vxc_short8 in, dst;
    vxc_short16 src;
    vxc_half8 paraHlf;
    VXC_ReadImage(in, input, coord.xy, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    src.hi = max(in, 0);
    src.lo = min(in, 0);

    unsigned short src2;
    _viv_asm(COPY, src2, multiplier, 2);
    VXC_DP2x8(paraHlf, alpha_hlf, src2, VXC_MODIFIER(0, 1, 0, VXC_RM_TowardZero, 0), uniMergeMultiplier_2x8);
    VXC_DP2x8_b(dst, src.hi, src.lo, paraHlf, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt16_2x8b);
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
}

#else
__kernel void leakyRelu_I8toI8_opt0
(
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
)
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));
    vxc_char16 in, dst;
    vxc_char16 src0, src1, src;
    VXC_ReadImage(in, input, coord.xy, 0, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    src0 = max(in, 0);
    src1 = min(in, 0);
    _viv_asm(COPY, src, src0, 16);
    src.s89abcdef = src1.s01234567;
    VXC_DP2x8(dst, src, alpha_hlf, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt8_2x8);
    _viv_asm(COPY, src, src1, 16);
    src.s01234567 = src0.s89abcdef;
    VXC_DP2x8(dst, src, alpha_hlf, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt8_2x8);
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0));
}

__kernel void leakyRelu_I16toI16_opt
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
    )
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));
    vxc_short8 in, dst;
    vxc_short8 src0, src1, src;
    VXC_ReadImage(in, input, coord.xy, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    src0 = max(in, 0);
    src1 = min(in, 0);
    _viv_asm(COPY, src, src0, 16);
    src.s4567 = src1.s0123;
    VXC_DP4x4(dst, src, alpha_hlf, VXC_MODIFIER(0, 3, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt16_4x4);
    _viv_asm(COPY, src, src1, 16);
    src.s0123 = src0.s4567;
    VXC_DP4x4(dst, src, alpha_hlf, VXC_MODIFIER(4, 7, 0, VXC_RM_ToNearestEven, 1), uniLeakyReluInt16_4x4);
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
}
#endif


_viv_uniform VXC_512Bits uniConvertData2F32_0_4x4;
_viv_uniform VXC_512Bits uniConvertData2F32_1_4x4;
_viv_uniform VXC_512Bits uniConvertInt32toUint8_2x8;
_viv_uniform float input_scale;
_viv_uniform float input_tail;
_viv_uniform float output_zp;

_viv_uniform VXC_512Bits uniU8SubZP_MulM_PStoF16Lo_2x8;
_viv_uniform VXC_512Bits uniU8SubZP_MulM_PStoF16Hi_2x8;
_viv_uniform VXC_512Bits uniF16MulF16_2x8;
_viv_uniform int inputZP;
_viv_uniform int outputZP;
_viv_uniform VXC_512Bits uniS16AddZP_2x8;

#define LEAKY_RELU_ASMMTRIC_2D(name, src_type, dst_type) \
__kernel void leakyRelu_##name##to##name##_2D \
    ( \
    __read_only  image2d_array_t input, \
    __write_only image2d_array_t output, \
                 float           alpha \
    ) \
{ \
    src_type src0, dst; \
    vxc_short8  vec0, vec1, vec2; \
    vxc_half8   param_h, src2, src3; \
    vxc_half16  src; \
    vxc_short8  const1 = (vxc_short8)(0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00); \
 \
    int2 coord = (int2)(get_global_id(0), get_global_id(1)); \
    VXC_ReadImage(src0, input, coord, 0, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0)); \
    half alpha_hlf; \
    _viv_asm(CONV, alpha_hlf, alpha); \
    _viv_asm(COPY, vec0, alpha_hlf, 4); \
 \
    src_type input_ZP; \
    _viv_asm(COPY, input_ZP, inputZP, 4); \
    VXC_DP2x8(src2, src0, input_ZP, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniU8SubZP_MulM_PStoF16Lo_2x8); \
    VXC_DP2x8(src3, src0, input_ZP, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniU8SubZP_MulM_PStoF16Hi_2x8); \
 \
    vec0 = vec0.s00000000; \
    _viv_asm(COPY, vec1, src2, 16); \
    vec2 = vec1 >= 0 ? const1 : vec0; \
    _viv_asm(COPY, param_h, vec2, 16); \
    VXC_DP2x8(vec2, src2, param_h, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniF16MulF16_2x8); \
    _viv_asm(COPY, src0, outputZP, 16); \
    VXC_DP2x8(dst, vec2, src0, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniS16AddZP_2x8); \
 \
    _viv_asm(COPY, vec1, src3, 16); \
    vec2 = vec1 >= 0 ? const1 : vec0; \
    _viv_asm(COPY, param_h, vec2, 16); \
    VXC_DP2x8(vec2, src3, param_h, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniF16MulF16_2x8); \
    VXC_DP2x8(dst, vec2, src0, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniS16AddZP_2x8); \
 \
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0)); \
}
LEAKY_RELU_ASMMTRIC_2D(U8, vxc_uchar16, vxc_uchar16)
LEAKY_RELU_ASMMTRIC_2D(I8, vxc_char16,  vxc_char16)

#define LEAKY_RELU_ASMMTRICTOF16_2D(name, src_type) \
__kernel void leakyRelu_##name##toF16_2D \
    ( \
    __read_only  image2d_array_t input, \
    __write_only image2d_array_t output, \
                 float           alpha \
    ) \
{ \
    src_type src0, dst; \
    vxc_short8  vec0, vec1, vec2; \
    vxc_half8   param_h, src2, src3; \
    vxc_half16  src; \
    vxc_short8  const1 = (vxc_short8)(0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00, 0x3c00); \
 \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(0), get_global_id(1)); \
    VXC_ReadImage(src0, input, coord.xy, 0, VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0)); \
    half alpha_hlf; \
    _viv_asm(CONV, alpha_hlf, alpha); \
    _viv_asm(COPY, vec0, alpha_hlf, 4); \
 \
    coord.z += 8; \
 \
    src_type input_ZP; \
    _viv_asm(COPY, input_ZP, inputZP, 4); \
    VXC_DP2x8(src2, src0, input_ZP, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniU8SubZP_MulM_PStoF16Lo_2x8); \
    VXC_DP2x8(src3, src0, input_ZP, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniU8SubZP_MulM_PStoF16Hi_2x8); \
 \
    vec0 = vec0.s00000000; \
    _viv_asm(COPY, vec1, src2, 16); \
    vec2 = vec1 >= 0 ? const1 : vec0; \
    _viv_asm(COPY, param_h, vec2, 16); \
    VXC_DP2x8(src2, src2, param_h, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniF16MulF16_2x8); \
    _viv_asm(COPY, vec2, src2, 16); \
    VXC_WriteImage(output, coord.xy, vec2, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
 \
    _viv_asm(COPY, vec1, src3, 16); \
    vec2 = vec1 >= 0 ? const1 : vec0; \
    _viv_asm(COPY, param_h, vec2, 16); \
    VXC_DP2x8(src3, src3, param_h, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniF16MulF16_2x8); \
    _viv_asm(COPY, vec2, src3, 16); \
 \
    VXC_WriteImage(output, coord.zy, vec2, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}
LEAKY_RELU_ASMMTRICTOF16_2D(U8, vxc_uchar16)
LEAKY_RELU_ASMMTRICTOF16_2D(I8, vxc_char16)

#define LEAKY_RELU_IMPL(name0, name1, src_type, copy_type, conv_type, dst_type) \
__kernel void leakyRelu_##name0##to##name1 \
    ( \
    __read_only  image2d_array_t input, \
    __write_only image2d_array_t output, \
                 float           alpha \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), get_global_id(2)); \
 \
    src_type vec; \
    copy_type src; \
    dst_type outval; \
    vxc_float4 imgData0, imgData1; \
 \
    VXC_ReadImage2DArray(vec, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    _viv_asm(COPY, src, vec, 16); \
 \
    VXC_DP4x4(imgData0, src, src, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniConvertData2F32_0_4x4); \
    VXC_DP4x4(imgData1, src, src, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniConvertData2F32_1_4x4); \
 \
    imgData0 = imgData0 * input_scale + input_tail; \
    imgData1 = imgData1 * input_scale + input_tail; \
 \
    vxc_float4 maxData0 = imgData0 >= 0 ? imgData0 : 0.0; \
    vxc_float4 maxData1 = imgData1 >= 0 ? imgData1 : 0.0; \
    vxc_float4 minData0 = imgData0 < 0 ? imgData0 : 0.0; \
    vxc_float4 minData1 = imgData1 < 0 ? imgData1 : 0.0; \
    imgData0 = maxData0 + alpha * minData0 + output_zp; \
    imgData1 = maxData1 + alpha * minData1 + output_zp; \
 \
    conv_type dst0, dst1; \
    _viv_asm(CONV_RTE, dst0, imgData0); \
    _viv_asm(CONV_RTE, dst1, imgData1); \
    VXC_DP2x8(outval, dst0, dst1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 1), uniConvertInt32toUint8_2x8); \
    VXC_WriteImage2DArray(output, coord, outval, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}
LEAKY_RELU_IMPL(U8,  U8,  vxc_uchar16, vxc_uchar16, int4,  vxc_uchar16)
LEAKY_RELU_IMPL(I8,  I8,  vxc_char16,  vxc_char16,  int4,  vxc_char16)
LEAKY_RELU_IMPL(I16, I16, vxc_short8,  vxc_short8,  int4,  vxc_short8)
LEAKY_RELU_IMPL(U8,  F16, vxc_uchar16, vxc_uchar16, half4, vxc_short8)
LEAKY_RELU_IMPL(I8,  F16, vxc_char16,  vxc_char16,  half4, vxc_short8)
LEAKY_RELU_IMPL(I16, F16, vxc_short8,  vxc_short8,  half4, vxc_short8)
LEAKY_RELU_IMPL(F16, I16, vxc_short8,  vxc_half8,   int4,  vxc_short8)
LEAKY_RELU_IMPL(F16, I8,  vxc_short8,  vxc_half8,   int4,  vxc_char16)
LEAKY_RELU_IMPL(F16, U8,  vxc_short8,  vxc_half8,   int4,  vxc_uchar16)

#define LEAKY_RELU_IMPL_2D(name0, name1, src_type, copy_type, conv_type, dst_type) \
__kernel void leakyRelu_##name0##to##name1##_2D \
    ( \
    __read_only  image2d_array_t input, \
    __write_only image2d_array_t output, \
                 float           alpha \
    ) \
{ \
    int2 coord = (int2)(get_global_id(0), get_global_id(1)); \
 \
    src_type vec; \
    copy_type src; \
    dst_type outval; \
    vxc_float4 imgData0, imgData1; \
 \
    VXC_ReadImage(vec, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
    _viv_asm(COPY, src, vec, 16); \
 \
    VXC_DP4x4(imgData0, src, src, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniConvertData2F32_0_4x4); \
    VXC_DP4x4(imgData1, src, src, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniConvertData2F32_1_4x4); \
 \
    imgData0 = imgData0 * input_scale + input_tail; \
    imgData1 = imgData1 * input_scale + input_tail; \
 \
    vxc_float4 maxData0 = imgData0 >= 0 ? imgData0 : 0.0; \
    vxc_float4 maxData1 = imgData1 >= 0 ? imgData1 : 0.0; \
    vxc_float4 minData0 = imgData0 < 0 ? imgData0 : 0.0; \
    vxc_float4 minData1 = imgData1 < 0 ? imgData1 : 0.0; \
    imgData0 = maxData0 + alpha * minData0 + output_zp; \
    imgData1 = maxData1 + alpha * minData1 + output_zp; \
 \
    conv_type dst0, dst1; \
    _viv_asm(CONV_RTE, dst0, imgData0); \
    _viv_asm(CONV_RTE, dst1, imgData1); \
    VXC_DP2x8(outval, dst0, dst1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 1), uniConvertInt32toUint8_2x8); \
    VXC_WriteImage(output, coord, outval, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0)); \
}
LEAKY_RELU_IMPL_2D(I16, I16, vxc_short8,  vxc_short8,  int4,  vxc_short8)
LEAKY_RELU_IMPL_2D(I16, F16, vxc_short8,  vxc_short8,  half4, vxc_short8)
LEAKY_RELU_IMPL_2D(F16, I16, vxc_short8,  vxc_half8,   int4,  vxc_short8)
LEAKY_RELU_IMPL_2D(F16, I8,  vxc_short8,  vxc_half8,   int4,  vxc_char16)
LEAKY_RELU_IMPL_2D(F16, U8,  vxc_short8,  vxc_half8,   int4,  vxc_uchar16)

_viv_uniform VXC_512Bits uniU8MulAndPostShift0_Lo_2x8;
_viv_uniform VXC_512Bits uniU8MulAndPostShift0_Hi_2x8;
_viv_uniform VXC_512Bits uniU8MulAndPostShift1_Lo_2x8;
_viv_uniform VXC_512Bits uniU8MulAndPostShift1_Hi_2x8;
_viv_uniform int2 multAndoutZP0;//[0:15] multiplier, [31:63] output zp
_viv_uniform int2 multAndoutZP1;//[0:15] multiplier, [31:63] output zp
_viv_uniform int4 packedInputZP;

#define LEAKY_RELU_ASMMTIC_OPT(name, src_type, dst_type) \
__kernel void leakyRelu_##name##to##name##_opt \
    ( \
    __read_only  image2d_array_t input, \
    __write_only image2d_array_t output, \
                 float           alpha \
    ) \
{ \
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0); \
    src_type src0, dst0, dst1, dst; \
    VXC_ReadImage2DArray(src0, input,coord, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0)); \
 \
    vxc_ushort8 multiplier; \
    _viv_asm(COPY, multiplier, multAndoutZP0, 16); \
    VXC_DP2x8(dst0, src0, multiplier, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift0_Lo_2x8); \
    VXC_DP2x8(dst0, src0, multiplier, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift0_Hi_2x8); \
    _viv_asm(COPY, multiplier, multAndoutZP1, 16); \
    VXC_DP2x8(dst1, src0, multiplier, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift1_Lo_2x8); \
    VXC_DP2x8(dst1, src0, multiplier, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift1_Hi_2x8); \
 \
    src_type zp; \
    _viv_asm(COPY, zp, packedInputZP, 16); \
    dst = src0 >= zp ? dst0 : dst1; \
 \
    VXC_WriteImage2DArray(output, coord, dst, VXC_MODIFIER(0, 15, 0,VXC_RM_TowardZero, 0)); \
}
LEAKY_RELU_ASMMTIC_OPT(U8, vxc_uchar16, vxc_uchar16)
LEAKY_RELU_ASMMTIC_OPT(I8, vxc_char16,  vxc_char16)

#define LEAKY_RELU_ASMMTIC_2D_OPT(name, src_type, dst_type) \
__kernel void leakyRelu_##name##to##name##_2D_opt \
    ( \
    __read_only  image2d_array_t input, \
    __write_only image2d_array_t output, \
                 float           alpha \
    ) \
{ \
    int2 coord = (int2)(get_global_id(0), get_global_id(1)); \
    src_type src0, dst0, dst1, dst; \
    VXC_ReadImage(src0, input,coord, VXC_5BITOFFSET_XY(0, 0), VXC_MODIFIER(0, 15, 0, VXC_RM_TowardZero, 0)); \
 \
    vxc_ushort8 multiplier; \
    _viv_asm(COPY, multiplier, multAndoutZP0, 16); \
    VXC_DP2x8(dst0, src0, multiplier, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift0_Lo_2x8); \
    VXC_DP2x8(dst0, src0, multiplier, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift0_Hi_2x8); \
    _viv_asm(COPY, multiplier, multAndoutZP1, 16); \
    VXC_DP2x8(dst1, src0, multiplier, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift1_Lo_2x8); \
    VXC_DP2x8(dst1, src0, multiplier, VXC_MODIFIER(8, 15, 0, VXC_RM_ToNearestEven, 1), uniU8MulAndPostShift1_Hi_2x8); \
 \
    src_type zp; \
    _viv_asm(COPY, zp, packedInputZP, 16); \
    dst = src0 >= zp ? dst0 : dst1; \
 \
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 15, 0,VXC_RM_TowardZero, 0)); \
}
LEAKY_RELU_ASMMTIC_2D_OPT(U8, vxc_uchar16, vxc_uchar16)
LEAKY_RELU_ASMMTIC_2D_OPT(I8, vxc_char16,  vxc_char16)

_viv_uniform VXC_512Bits UniFP16Mul_dp2x8;
__kernel void leakyRelu_F16toF16_2D
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
    )
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));

    vxc_short8 img1_s16, para_s16, val_s16;
    vxc_half8 img_fp16, para_fp16, val_fp16;

    VXC_ReadImage(img1_s16, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    _viv_asm(COPY, para_s16, alpha_hlf, 4);

    _viv_asm(COPY, para_fp16, para_s16, 16);
    _viv_asm(COPY, img_fp16, img1_s16, 16);
    VXC_DP2x8(val_fp16, img_fp16, para_fp16, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), UniFP16Mul_dp2x8);
    vxc_short8 mulData;
    _viv_asm(COPY, mulData, val_fp16, 16);
    val_s16 = img1_s16 > 0 ? img1_s16 : mulData;
    VXC_WriteImage(output, coord, val_s16, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
}

__kernel void leakyRelu_F16toF16
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0);
    int4 coord_para = (int4)(coord.z, 0, 0, 0);

    vxc_short8 img1_s16, para_s16, val_s16;
    vxc_half8 img_fp16, para_fp16, val_fp16;

    VXC_ReadImage2DArray(img1_s16, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
    half alpha_hlf;
    _viv_asm(CONV, alpha_hlf, alpha);
    _viv_asm(COPY, para_s16, alpha_hlf, 4);

    _viv_asm(COPY, para_fp16, para_s16, 16);
    _viv_asm(COPY, img_fp16, img1_s16, 16);
    VXC_DP2x8(val_fp16, img_fp16, para_fp16, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), UniFP16Mul_dp2x8);
    vxc_short8 mulData;
    _viv_asm(COPY, mulData, val_fp16, 16);
    val_s16 = img1_s16 > 0 ? img1_s16 : mulData;
    VXC_WriteImage2DArray(output, coord, val_s16, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
}

_viv_uniform VXC_512Bits uniConvBF16toF32_Part0_2x8;
_viv_uniform VXC_512Bits uniConvBF16toF32_Part1_2x8;
_viv_uniform VXC_512Bits uniExtractOddData_2x8;
__kernel void leakyRelu_BF16toBF16
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(2), 0);
    vxc_ushort8   src0, src1, dst;
    VXC_ReadImage2DArray(src0, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
    float4 vecA;
    float4 vecB;
    vxc_short8 zero = (vxc_short8)(0, 0, 0, 0, 0, 0, 0, 0);
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part0_2x8);
    _viv_asm(COPY, vecA, src1, 16);
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part1_2x8);
    _viv_asm(COPY, vecB, src1, 16);
    vecA = vecA >= 0 ? vecA : vecA * alpha;
    vecB = vecB >= 0 ? vecB : vecB * alpha;
    _viv_asm(COPY, src0, vecA, 16);
    _viv_asm(COPY, src1, vecB, 16);
    VXC_DP2x8(dst, src0, src1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniExtractOddData_2x8);
    VXC_WriteImage2DArray(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
}

__kernel void leakyRelu_BF16toBF16_2D
    (
    __read_only  image2d_array_t input,
    __write_only image2d_array_t output,
                 float           alpha
    )
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));
    vxc_ushort8   src0, src1, dst;
    VXC_ReadImage(src0, input, coord, 0, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
    float4 vecA;
    float4 vecB;
    vxc_short8 zero = (vxc_short8)(0, 0, 0, 0, 0, 0, 0, 0);
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part0_2x8);
    _viv_asm(COPY, vecA, src1, 16);
    VXC_DP2x8(src1, src0, zero, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniConvBF16toF32_Part1_2x8);
    _viv_asm(COPY, vecB, src1, 16);
    vecA = vecA >= 0 ? vecA : vecA * alpha;
    vecB = vecB >= 0 ? vecB : vecB * alpha;
    _viv_asm(COPY, src0, vecA, 16);
    _viv_asm(COPY, src1, vecB, 16);
    VXC_DP2x8(dst, src0, src1, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0), uniExtractOddData_2x8);
    VXC_WriteImage(output, coord, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
}
